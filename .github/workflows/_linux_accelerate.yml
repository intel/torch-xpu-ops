name: Linux Accelerate Test

on:
  schedule:
    # GMT+8 0:00 Sunday
    - cron: '0 16 * * 6'
  pull_request:
    branches:
      - main
    paths:
      - '.github/scripts/parse-junitxml.py'
      - '.github/actions/print-environment/action.yml'
      - '.github/workflows/_linux_accelerate.yml'
  workflow_dispatch:
    inputs:
      pytorch:
        required: false
        type: string
        default: 'nightly'
        description: Pytorch branch/commit
      python:
        required: false
        type: string
        default: '3.10'
        description: Python version
      runner:
        required: true
        type: string
        default: 'pvc_rolling'
        description: Runner label
      accelerate:
        required: false
        type: string
        default: 'v1.6.0'
        description: Accelerate version
      transformers:
        required: false
        type: string
        default: 'v4.51.3'
        description: Transformers version

permissions: read-all

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true
env:
  TORCH_INDEX: '--pre --index-url https://download.pytorch.org/whl/nightly/xpu'

defaults:
  run:
    shell: bash {0}
env:
  GH_TOKEN: ${{ github.token }}
  DOCKER_REGISTRY_AUTH_TOKEN: ${{ secrets.DOCKER_HUB_TOKEN }}

jobs:
  conditions-filter:
    name: conditions-filter
    if: ${{ github.event.pull_request.draft == false }}
    runs-on: ubuntu-24.04
    timeout-minutes: 10
    outputs:
      disabled_tests: ${{ steps.check-pr-desc.outputs.disabled_tests }}
    steps:
      - name: Check PR infos
        id: check-pr-desc
        run: |
          set -x -e -o pipefail
          sudo apt update && sudo apt install -y dos2unix
          (gh --repo ${GITHUB_REPOSITORY} pr view ${{ github.event.pull_request.number }} || echo $?) 2>&1 |tee pr-info.txt
          dos2unix pr-info.txt
          disabled_tests="$(awk '/disable_/{printf("%s ", $0)}' pr-info.txt)"
          echo "disabled_tests=${disabled_tests}" |tee "${GITHUB_OUTPUT}"

  prepare:
    runs-on: ${{ inputs.runner != '' && inputs.runner || 'pvc_rolling' }}
    needs: conditions-filter
    if: ${{ !(contains(needs.conditions-filter.outputs.disabled_tests, 'disable_all') || contains(needs.conditions-filter.outputs.disabled_tests, 'disable_accelerate')) }}
    outputs:
      runner_id: ${{ steps.runner-info.outputs.runner_id }}
      user_id: ${{ steps.runner-info.outputs.user_id }}
      render_id: ${{ steps.runner-info.outputs.render_id }}
      hostname: ${{ steps.runner-info.outputs.hostname }}
      pytest_extra_args: ${{ steps.runner-info.outputs.pytest_extra_args }}
    steps:
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Get runner
        id: runner-info
        uses: ./.github/actions/get-runner

  tests:
    runs-on: ${{ needs.prepare.outputs.runner_id }}
    needs: prepare
    container:
      image: mengfeili/intel-pvc-driver:1146-1136
      volumes:
        - ${{ github.workspace }}:${{ github.workspace }}
      options: --device=/dev/mem --device=/dev/dri --group-add video --group-add ${{ needs.prepare.outputs.render_id }}
              --security-opt seccomp=unconfined --cap-add=SYS_PTRACE --shm-size=8g
              -u ${{ needs.prepare.outputs.user_id }}
              -e ZE_AFFINITY_MASK
      env:
        WORK_DIR: 'accelerate'
        PYTORCH_DEBUG_XPU_FALLBACK: 1
        HF_HUB_ETAG_TIMEOUT: 120
        HF_HUB_DOWNLOAD_TIMEOUT: 120
        PARSE_JUNIT: ${{ github.workspace }}/torch-xpu-ops/.github/scripts/parse-junitxml.py
        AGENT_TOOLSDIRECTORY: /tmp/xpu-tool
        # Usage of `--dist loadfile` is a must as HF tests has complex setups including
        # setUpClass and @first_run clauses. So 'loadfile' stratagy allows to minimize
        # race conditions scope.
        PYTEST_ADDOPTS: -rsf --timeout 600 --timeout_method=thread --dist loadfile ${{ needs.prepare.outputs.pytest_extra_args }}
        VIRTUAL_ENV: ${{ github.workspace }}/.venv
    env:
      accelerate: ${{ inputs.accelerate != '' && inputs.accelerate || 'v1.6.0' }}
      transformers: ${{ inputs.transformers != '' && inputs.transformers || 'v4.51.3' }}
      python: ${{ inputs.python != '' && inputs.python || '3.10' }}
    steps:
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
        with:
          path: torch-xpu-ops
      - name: Checkout Accelerate
        uses: actions/checkout@v4
        with:
          repository: huggingface/accelerate
          ref: ${{ env.accelerate }}
          path: accelerate
      - name: Install uv and python-${{ env.python }}
        uses: astral-sh/setup-uv@v6
        with:
          python-version: ${{ env.python }}
      - name: Prepare environment
        run: |
          sudo apt-get update
          # pciutils is needed to report available GPUs (we use lspci)
          # python3-dev is needed for torch inductor and extension compilations
          sudo apt-get install -y --no-install-recommends pciutils python3-dev
          rm -rf $VIRTUAL_ENV
          uv venv $VIRTUAL_ENV
          # Add path to virtual environment bin folder to make
          # python and other executables visible
          echo "$VIRTUAL_ENV/bin/" >> $GITHUB_PATH
      - name: Check python
        run: |
          which python && python -V
      - name: Install pytorch and deps
        run: |
          uv pip install $TORCH_INDEX torch torchvision torchaudio
          # Do NOT install HF transformers or accelerate before torch as we need
          # very specific version of the torch and HF would bring its own.
          uv pip install \
            junitparser \
            pytest \
            pytest-timeout \
            pytest-xdist \
            transformers==${{ env.transformers }}
      - name: Prepare Accelerate
        run: |
          cd $WORK_DIR
          uv pip install -e .
          uv pip install -e ".[testing]"
          rm -rf tests_log && mkdir -p tests_log
          rm -rf reports
          cp ${{ github.workspace }}/torch-xpu-ops/.github/scripts/spec.py ./
      - name: Report installed versions
        run: |
          echo "pip installed packages:"
          uv pip list | tee ${{ github.workspace }}/$WORK_DIR/tests_log/pip_list.txt
          echo "lspci gpu devices:"
          lspci -d ::0380 | tee ${{ github.workspace }}/$WORK_DIR/tests_log/lspci_0380.txt
          echo "GPU render nodes:"
          cat /sys/class/drm/render*/device/device | tee ${{ github.workspace }}/$WORK_DIR/tests_log/device_IDs.txt
          echo "xpu-smi output:"
          xpu-smi discovery -y --json --dump -1
      - name: Sanity check installed packages
        run: |
          # These checks are to exit earlier if for any reason torch
          # packages were reinstalled back to CUDA versions (not expected).
          uv pip show torch | grep Version | grep xpu
          uv pip show torchaudio | grep Version | grep xpu
          uv pip show torchvision | grep Version | grep xpu
          python -c 'import torch; exit(not torch.xpu.is_available())'
          printenv
      - name: Run tests on ${{ needs.prepare.outputs.hostname }}
        run: |
          cd $WORK_DIR && rm -rf reports && mkdir -p reports
          # Excluding tests due to:
          # * tests/test_examples.py::FeatureExamplesTests::test_profiler fails on
          #   Kineto profiler initialization for XPU device: PTI_ERROR_INTERNAL
          # * tests/test_cli.py::ModelEstimatorTester::test_gated for failures due
          #   to not root caused environment configuration issue
          # * tests/test_big_modeling.py::test_dispatch_model_tied_weights_memory_with_nested_offload_cpu fails
          #   with OOM. That's a new test added by https://github.com/huggingface/accelerate/pull/3445
          pattern="not test_profiler and not test_gated and not test_dispatch_model_tied_weights_memory_with_nested_offload_cpu"
          cmd=(python -m pytest --junitxml=reports/accelerate.xml -k "$pattern" tests/)
          {
            echo "### Running"
            echo "\`\`\`"
            echo "${cmd[@]@Q}"
            echo "\`\`\`"
          } >> $GITHUB_STEP_SUMMARY
          "${cmd[@]}"
      - name: Print result tables
        if: ${{ ! cancelled() }}
        run: |
          cd $WORK_DIR
          {
            echo "### Results"
            python $PARSE_JUNIT reports/accelerate.xml --stats
            echo "### Failed"
            python $PARSE_JUNIT reports/accelerate.xml --errors --failed
            echo "### Skipped"
            python $PARSE_JUNIT reports/accelerate.xml --skipped
          } >> $GITHUB_STEP_SUMMARY
      - name: Print environment
        if: ${{ ! cancelled() }}
        uses: ./torch-xpu-ops/.github/actions/print-environment
        with:
          pip_packages: 'accelerate transformers'
      - name: Upload Test log
        if: ${{ ! cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: Torch-XPU-Accelerate-Log-${{ github.event.pull_request.number || github.sha }}
          path: |
            ${{ github.workspace }}/accelerate/reports
            ${{ github.workspace }}/accelerate/tests_log
