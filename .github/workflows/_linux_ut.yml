name: Linux UT Test

on:
  workflow_call:
    inputs:
      pytorch:
        required: false
        type: string
        default: 'main'
        description: Pytorch branch/commit
      keep_torch_xpu_ops:
        required: false
        type: string
        default: 'false'
        description: Keep torch-xpu-ops pin. `true` means use pined commit
      triton:
        required: false
        type: string
        default: ''
        description: Triton commit. Use pytorch pined commit by default
      ut:
        required: true
        type: string
        default: ''
        description: UT scope. `op_regression,op_regression_dev1,op_transformers,op_extended,op_ut,torch_xpu` Delimiter is comma
      disabled_tests:
        required: false
        type: string
        default: ''
        description: List disabled tests, such as disable_ut or disable_distributed
      python:
        required: false
        type: string
        default: '3.10'
        description: Python version
      runner:
        required: true
        type: string
        default: 'linux.idc.xpu'
        description: Runner label
      driver:
        required: false
        type: string
        default: 'lts'
        description: Driver lts/rolling

permissions: read-all

jobs:
  ut_test:
    runs-on: ${{ matrix.test.runner || inputs.runner }}
    if: ${{ inputs.ut != 'xpu_distributed' && !contains(inputs.disabled_tests, 'disable_ut') }}
    timeout-minutes: 300
    env:
      GH_TOKEN: ${{ github.token }}
      NEOReadDebugKeys: ${{ inputs.driver == 'rolling' && '1' || '0' }}
      DisableScratchPages: ${{ inputs.driver == 'rolling' && '1' || '0' }}
      ut_skip_issue: 1624
    strategy:
      fail-fast: false
      matrix:
        test:
          - name: 'op_regression'
            condition: ${{ contains(inputs.ut, 'op_regression') }}
            directory: 'test/regressions'
            command: 'pytest --timeout 600 --timeout_method=thread -v --junit-xml=../../ut_log/op_regression.xml'
            log_prefix: 'op_regression'
            additional_steps: |
              clinfo --list
              pip install pytest pytest-timeout
          - name: 'op_regression_dev1'
            condition: ${{ contains(inputs.ut, 'op_regression_dev1') }}
            directory: 'test/regressions'
            command: 'pytest --timeout 600 --timeout_method=thread -v test_operation_on_device_1.py --junit-xml=$GITHUB_WORKSPACE/ut_log/op_regression_dev1.xml'
            log_prefix: 'op_regression_dev1'
            additional_steps: |
              clinfo --list
              unset ZE_AFFINITY_MASK
              pip install pytest pytest-timeout
            runner: 'pvc_e2e'
          - name: 'op_transformers'
            condition: ${{ contains(inputs.ut, 'op_transformers') }}
            directory: '../pytorch'
            command: 'pytest --timeout 600 --timeout_method=thread -v test/test_transformers.py -k xpu --junit-xml=$GITHUB_WORKSPACE/ut_log/op_transformers.xml'
            log_prefix: 'op_transformers'
            additional_steps: |
              pip install pytest pytest-timeout
              export PYTORCH_TEST_WITH_SLOW=1
          - name: 'op_extended'
            condition: ${{ contains(inputs.ut, 'op_extended') }}
            directory: '../pytorch/third_party/torch-xpu-ops/test/xpu/extended/'
            command: 'python run_test_with_skip.py'
            log_prefix: 'op_extended'
            additional_steps: |
              pip install pytest pytest-timeout
              export PYTORCH_TEST_WITH_SLOW=1
            xml_post_processing: |
              cp op_extended.xml $GITHUB_WORKSPACE/ut_log
          - name: 'op_ut'
            condition: ${{ contains(inputs.ut, 'op_ut') }}
            directory: '../pytorch/third_party/torch-xpu-ops/test/xpu'
            log_prefix: 'op_ut'
            command_script: |
              export PYTORCH_ENABLE_XPU_FALLBACK=1
              export PYTORCH_TEST_WITH_SLOW=1
              python run_test_with_skip.py \
                2>$GITHUB_WORKSPACE/ut_log/op_ut/op_ut_with_skip_test_error.log | \
                tee $GITHUB_WORKSPACE/ut_log/op_ut/op_ut_with_skip_test.log
              cp *.xml $GITHUB_WORKSPACE/ut_log
              find op_ut_with_skip_nn op_ut_with_skip_quantization/core -type f -exec sh -c '
                  dir_path=$(dirname "$1");
                  case "$dir_path" in
                      *"op_ut_with_skip_quantization/core"*)
                          dir_name="op_ut_with_skip_quantization_core";;
                      *)
                          dir_name=$(basename "$dir_path");;
                  esac;
                  mv "$1" "$dir_path/${dir_name}_$(basename "$1")"
              ' _ {} \;
              cp op_ut_with_skip_nn/*.xml $GITHUB_WORKSPACE/ut_log
              cp op_ut_with_skip_quantization/core/*.xml $GITHUB_WORKSPACE/ut_log
              # Cases run with a on-demand white list, since some suites are too
              # slow to go through all operators on CPU. So add cases on-demand
              # when XPU implementatoin is done.
              # test_foreach, test_decomp
              # Run with only
              timeout 10000 python run_test_with_only.py \
                2>$GITHUB_WORKSPACE/ut_log/op_ut/op_ut_with_only_test_error.log | \
                tee $GITHUB_WORKSPACE/ut_log/op_ut/op_ut_with_only_test.log
              cp op_ut_with_only.xml $GITHUB_WORKSPACE/ut_log
            additional_steps: |
              pip install pytest pytest-timeout
          - name: 'torch_xpu'
            condition: ${{ contains(inputs.ut, 'torch_xpu') }}
            directory: '../pytorch'
            command_script: |
              export PYTORCH_TEST_WITH_SLOW=1
              export PYTORCH_TESTING_DEVICE_ONLY_FOR="xpu"
              test_cmd="python test/run_test.py --include "
              for test in $(ls test/inductor | grep test); do test_cmd="${test_cmd} inductor/$test"; done
              for test in $(ls test/xpu | grep test); do test_cmd="${test_cmd} xpu/$test"; done
              if [ -f "test/test_xpu.py" ]; then test_cmd="${test_cmd} test_xpu.py"; fi
              eval $test_cmd 2>$GITHUB_WORKSPACE/ut_log/torch_xpu/torch_xpu_test_error.log | \
                tee $GITHUB_WORKSPACE/ut_log/torch_xpu/torch_xpu_test.log
            log_prefix: 'torch_xpu'
            additional_steps: |
              pip install pytest pytest-timeout
          - name: 'xpu_profiling'
            condition: ${{ inputs.driver == 'rolling' && contains(inputs.ut, 'xpu_profiling') }}
            command_script: |
              # RN50 Test
              PROFILE=1 python -u test/profiling/rn50.py -a resnet50 --dummy ./ --num-iterations 20 --xpu 0
              cp profiling.fp32.train.pt $GITHUB_WORKSPACE/ut_log/profile_test

              # All Issue Reproduce UT
              python -u test/profiling/correlation_id_mixed.py | \
                tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/correlation_id_mixed.log
              python -u test/profiling/reproducer.missing.gpu.kernel.time.py | \
                tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/reproducer.missing.gpu.kernel.time.log
              python -u test/profiling/time_precision_in_profile.py | \
                tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/time_precision_in_profile.log
              python -u test/profiling/profile_partial_runtime_ops.py | \
                tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/profile_partial_runtime_ops.log
              python -u test/profiling/triton_xpu_ops_time.py | \
                tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/triton_xpu_ops_time.log

              # All xpu ut under test/profiler
              cd ../pytorch/test/profiler
              python -m pytest --timeout 600 -vs test_cpp_thread.py | \
                tee $GITHUB_WORKSPACE/ut_log/profile_test/test_cpp_thread.log
              python -m pytest --timeout 600 -vs test_execution_trace.py | \
                tee $GITHUB_WORKSPACE/ut_log/profile_test/test_execution_trace.log
              python -m pytest --timeout 600 -vs test_memory_profiler.py | \
                tee $GITHUB_WORKSPACE/ut_log/profile_test/test_memory_profiler.log
              python -m pytest --timeout 600 -vs test_profiler_tree.py | \
                tee $GITHUB_WORKSPACE/ut_log/profile_test/test_profiler_tree.log
            additional_steps: |
              pip install pytest pytest-timeout
              mkdir -p ut_log/profile_test/issue_reproduce
    outputs: 
      ut_name: ${{ steps.set-output.outputs.UT_NAME || '' }}
    steps:
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Create unique workspace
        shell: bash -xe {0}
        run: |
          # Create unique conda env for each UT test
          random=$(head /dev/urandom | tr -dc A-Za-z0-9_ | head -c ${1:-5} | xargs)
          echo "CONDA_ENV_NAME=xpu_op_${ZE_AFFINITY_MASK}_${{ matrix.test.name }}_${random}" >> $GITHUB_ENV
      - name: Create Conda Env
        shell: bash -xe {0}
        run: |
          pwd
          which conda
          conda remove --all -y -n $CONDA_ENV_NAME || \
                rm -rf $(dirname ${CONDA_EXE})/../envs/$CONDA_ENV_NAME
          conda create -n $CONDA_ENV_NAME python=${{ inputs.python }} cmake ninja -y
          source activate $CONDA_ENV_NAME
      - name: Download Pytorch wheel
        if: ${{ inputs.pytorch != 'nightly_wheel' }}
        uses: actions/download-artifact@v4
        with:
          name: Torch-XPU-Wheel-${{ github.event.pull_request.number || github.sha }}
      - name: Prepare Stock Pytorch
        shell: bash -xe {0}
        run: |
          cd ../
          rm -rf ./pytorch || sudo rm -rf ./pytorch
          git clone https://github.com/pytorch/pytorch pytorch
          source activate $CONDA_ENV_NAME
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            pip install --force-reinstall ${{ github.workspace }}/torch*.whl
            TORCH_COMMIT_ID=$(python -c 'import torch; print(torch.version.git_version)')
            cd ./pytorch
            git checkout ${TORCH_COMMIT_ID}
            rm -rf vision || sudo rm -rf vision
            git clone https://github.com/pytorch/vision && cd vision && python setup.py install && cd ..
          else
            pip install torch torchvision torchaudio --pre --index-url https://download.pytorch.org/whl/nightly/xpu
            TORCH_COMMIT_ID=$(python -c 'import torch; print(torch.version.git_version)')
            cd ./pytorch
            git checkout ${TORCH_COMMIT_ID}
          fi
          pip install requests
          python ../torch-xpu-ops/.github/scripts/apply_torch_pr.py
          git show -s && git status && git diff
          pip install -r .ci/docker/requirements-ci.txt
      - name: Prepare Torch-xpu-ops
        shell: bash -xe {0}
        run: |
          cd ../pytorch
          rm -rf third_party/torch-xpu-ops
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            cp -r ${{ github.workspace }} third_party
          else
            TORCH_XPU_OPS_COMMIT=$(<third_party/xpu.txt)
            git clone https://github.com/intel/torch-xpu-ops.git third_party/torch-xpu-ops
            cd third_party/torch-xpu-ops
            git checkout ${TORCH_XPU_OPS_COMMIT}
          fi
      - name: Download Triton wheel
        if: ${{ inputs.pytorch != 'nightly_wheel' }}
        uses: actions/download-artifact@v4
        with:
          name: Triton-Wheel-${{ github.event.pull_request.number || github.sha }}
          path: ${{ github.workspace }}
      - name: Install Triton
        shell: bash -xe {0}
        run: |
          source activate $CONDA_ENV_NAME
          pip install --force-reinstall ${{ github.workspace }}/pytorch_triton_xpu-*.whl
      - name: Torch Config
        shell: bash -xe {0}
        run: |
          source activate $CONDA_ENV_NAME
          python -c "import torch; print(torch.__config__.show())"
          python -c "import torch; print(torch.__config__.parallel_info())"
          python -c "import torch; print(torch.__config__.torch.xpu.device_count())"
          python -c "import triton; print(triton.__version__)"

          cd ..
          python pytorch/torch/utils/collect_env.py
          rm -rf /tmp/torchinductor_* || sudo rm -rf /tmp/torchinductor_*
          rm -rf ~/.triton/cache || sudo rm -rf ~/.triton/cache
          echo "UT_NAME=${{ matrix.test.name }}" >> "${GITHUB_ENV}"
      - name: Run XPU UT Test
        shell: bash -xe {0}
        if: ${{ matrix.test.condition }}
        run: |
          set -e
          mkdir -p ${{ github.workspace }}/ut_log
          mkdir -p ${{ github.workspace }}/ut_log/${{ matrix.test.name }}
          source activate $CONDA_ENV_NAME
          echo "Running ${{ matrix.test.name }}"
          echo "Directory: ${{ matrix.test.directory }}"
          ${{ matrix.test.additional_steps }}

          cd ${{ matrix.test.directory }}

          if [[ "${{ matrix.test.name }}" == "op_ut" ]] || [[ "${{ matrix.test.name }}" == "xpu_profiling" ]] || [[ "${{ matrix.test.name }}" == "torch_xpu" ]]; then
            bash << "SCRIPT"
            set -e
            ${{ matrix.test.command_script }}
          SCRIPT
          else
            ${{ matrix.test.command }} \
              2>${{ github.workspace }}/ut_log/${{ matrix.test.name }}/${{ matrix.test.log_prefix }}_test_error.log | \
              tee ${{ github.workspace }}/ut_log/${{ matrix.test.name }}/${{ matrix.test.log_prefix }}_test.log
            ${{ matrix.test.xml_post_processing || '' }}
          fi
      - name: UT Test Results Summary
        shell: bash -xe {0}
        if: ${{ matrix.test.condition }}
        run: |
          source activate $CONDA_ENV_NAME
          pip install junitparser
          python .github/scripts/check-ut.py ${{ github.workspace }}/ut_log/*.xml >> $GITHUB_STEP_SUMMARY || true
          if [ -e "ut_failure_list.csv" ];then
              cp ut_failure_list.csv ${{ github.workspace }}/ut_log/ut_failure_list.csv
          fi
      - name: Clean up
        if: ${{ always() }}
        run: |
          if [ -n "$CONDA_ENV_NAME" ]; then
            conda remove --all -y -n $CONDA_ENV_NAME || rm -rf $(dirname ${CONDA_EXE})/../envs/$CONDA_ENV_NAME
          fi
      - name: Upload Inductor XPU UT Log
        if: ${{ matrix.test.condition }}
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-XPU-UT-Data-${{ github.event.pull_request.number || github.sha }}-${{ env.UT_NAME }}
          path: ${{ github.workspace }}/ut_log
      - name: Upload XPU UT Failure list
        if: ${{ matrix.test.condition }}
        uses: actions/upload-artifact@v4
        with:
          name: XPU-UT-Failure-List-${{ github.event.pull_request.number || github.sha }}-${{ env.UT_NAME }}
          path: ${{ github.workspace }}/ut_log/ut_failure_list.csv
      - name: Set UT outputs
        id: set-output
        if: ${{ matrix.test.condition }}
        run: |
          echo "UT_NAME=${{ matrix.test.name }}" >> $GITHUB_OUTPUT
  
  ut_test_results_check:
    needs: ut_test
    runs-on: ubuntu-22.04
    timeout-minutes: 30
    env:
      GH_TOKEN: ${{ github.token }}
      ut_skip_issue: 1624
    strategy:
      fail-fast: false
      matrix:
        test: 
        - name: 'op_regression'
          condition: ${{ contains(inputs.ut, 'op_regression') }}
        - name: 'op_regression_dev1'
          condition: ${{ contains(inputs.ut, 'op_regression_dev1') }}
        - name: 'op_transformers'
          condition: ${{ contains(inputs.ut, 'op_transformers') }}
        - name: 'op_extended'
          condition: ${{ contains(inputs.ut, 'op_extended') }}
        - name: 'op_ut'
          condition: ${{ contains(inputs.ut, 'op_ut') }}
        - name: 'torch_xpu'
          condition: ${{ contains(inputs.ut, 'torch_xpu') }}
        - name: 'xpu_profiling'
          condition: ${{ inputs.driver == 'rolling' && contains(inputs.ut, 'xpu_profiling') }}
    steps:
      - name: Get matrix UT value
        run: |
          echo "UT_NAME=${{ needs.ut_test.outputs.ut_name }}" >> "${GITHUB_ENV}"
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Download XPU UT Logs
        if: ${{ matrix.test.condition }}
        uses: actions/download-artifact@v4
        with:
          name: Inductor-XPU-UT-Data-${{ github.event.pull_request.number || github.sha }}-${{ matrix.test.name }}
          path: ${{ github.workspace }}/ut_log
      - name: Check UT Results
        if: ${{ matrix.test.condition }}
        shell: bash
        run: |
          repo="${{ github.repository }}"
          function contains() {
              contains_status="echo 'Start $2 ...'"
              {
                [[ $1 =~ (^|,)$2($|,) ]]
              } || {
                echo "[Warning] $2 is not suppotted type! Skipped!"
                contains_status="continue"
              }
          }
          set -xe
          cd ${{ github.workspace }}/ut_log/${{ matrix.test.name }}
          gh --repo $repo issue view $ut_skip_issue --json body -q .body | sed '/^$/d' > Known_issue.log
          gh api "repos/${{ github.repository }}/issues?labels=skipped" \
          --jq '.[] | select(.pull_request == null) | "Issue #\(.number): \(.title)\n\(.body)\n"' \
          > issues.log
          awk '/Cases:/ {flag=1; next} /^\|\||^$/ {flag=0} flag' issues.log | grep -Eo 'test[^[:space:]]+( \|\| [^[:space:]]+)?' | sed 's/ *|| */ /g' | sort -u > issues_temp.log
          awk '$2 == "op_ut" {print $1}' issues_temp.log > issues_op_ut.log
          cat issues_temp.log | awk '{print $1}' >> Known_issue.log
          awk -F'::' '{print $1}' issues_op_ut.log | sort -u | paste -sd ',' >> Known_issue.log
          cp ${{ github.workspace }}/.github/scripts/ut_result_check.sh ./
          bash ut_result_check.sh ${{ matrix.test.name }}
      - name: Upload Inductor XPU UT Log
        if: ${{ matrix.test.condition }}
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-XPU-UT-Data-${{ github.event.pull_request.number || github.sha }}-${{ matrix.test.name }}-checked
          path: ${{ github.workspace }}/ut_log

  distributed_ut_test:
    runs-on: pytorch-06
    if: ${{ contains(inputs.ut, 'xpu_distributed') && !contains(inputs.disabled_tests, 'disable_distribute') }}
    timeout-minutes: 60
    env:
      GH_TOKEN: ${{ github.token }}
      NEOReadDebugKeys: ${{ inputs.driver == 'rolling' && '1' || '0' }}
      DisableScratchPages: ${{ inputs.driver == 'rolling' && '1' || '0' }}
      ut_skip_issue: 1624
    steps:
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Create Conda Env
        run: |
          pwd
          which conda && conda clean -ay
          conda remove --all -y -n xpu_op_${ZE_AFFINITY_MASK} || \
                rm -rf $(dirname ${CONDA_EXE})/../envs/xpu_op_${ZE_AFFINITY_MASK}
          conda create -n xpu_op_${ZE_AFFINITY_MASK} python=${{ inputs.python }} cmake ninja -y
          source activate xpu_op_${ZE_AFFINITY_MASK}
      - name: Download Pytorch wheel
        if: ${{ inputs.pytorch != 'nightly_wheel' }}
        uses: actions/download-artifact@v4
        with:
          name: Torch-XPU-Wheel-${{ github.event.pull_request.number || github.sha }}
      - name: Prepare Stock Pytorch
        run: |
          cd ../
          rm -rf ./pytorch || sudo rm -rf ./pytorch
          git clone https://github.com/pytorch/pytorch pytorch
          source activate xpu_op_${ZE_AFFINITY_MASK}
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            pip install --force-reinstall ${{ github.workspace }}/torch*.whl
            TORCH_COMMIT_ID=$(python -c 'import torch; print(torch.version.git_version)')
            cd ./pytorch
            git checkout ${TORCH_COMMIT_ID}
            rm -rf vision || sudo rm -rf vision
            git clone https://github.com/pytorch/vision && cd vision && python setup.py install && cd ..
          else
            pip install torch torchvision torchaudio --pre --index-url https://download.pytorch.org/whl/nightly/xpu
            TORCH_COMMIT_ID=$(python -c 'import torch; print(torch.version.git_version)')
            cd ./pytorch
            git checkout ${TORCH_COMMIT_ID}
          fi
          pip install requests
          python ../torch-xpu-ops/.github/scripts/apply_torch_pr.py
          git show -s && git status && git diff
          pip install -r .ci/docker/requirements-ci.txt
      - name: Prepare Torch-xpu-ops
        run: |
          cd ../pytorch
          rm -rf third_party/torch-xpu-ops
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            cp -r ${{ github.workspace }} third_party
          else
            TORCH_XPU_OPS_COMMIT=$(<third_party/xpu.txt)
            git clone https://github.com/intel/torch-xpu-ops.git third_party/torch-xpu-ops
            cd third_party/torch-xpu-ops
            git checkout ${TORCH_XPU_OPS_COMMIT}
          fi
      - name: Triton Installation
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ../pytorch
          if [ -z ${{ inputs.triton }} ]; then
            TRITON_COMMIT_ID="$(<.ci/docker/ci_commit_pins/triton-xpu.txt)"
          else
            TRITON_COMMIT_ID="${{ inputs.triton }}"
          fi
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            pip install cmake ninja pybind11
            rm -rf pytorch_triton_xpu-*.whl
            TRITON_VERSION_NAME="$(
              curl -sSL https://raw.githubusercontent.com/intel/intel-xpu-backend-for-triton/${TRITON_COMMIT_ID}/python/triton/__init__.py 2>&1 |\
                      grep '__version__' |head -n 1 |awk -F "'" '{print $2}'
            )"
            python .github/scripts/build_triton_wheel.py --device xpu --commit-hash ${TRITON_COMMIT_ID} --triton-version ${TRITON_VERSION_NAME}
            pip install pytorch_triton_xpu-*.whl
          fi
      - name: Torch Config
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          python -c "import torch; print(torch.__config__.show())"
          python -c "import torch; print(torch.__config__.parallel_info())"
          python -c "import torch; print(torch.__config__.torch.xpu.device_count())"
          python -c "import triton; print(triton.__version__)"
          cd ..
          python pytorch/torch/utils/collect_env.py
          rm -rf /tmp/torchinductor_* || sudo rm -rf /tmp/torchinductor_*
          rm -rf ~/.triton/cache || sudo rm -rf ~/.triton/cache
      - name: Set Ptrace_scope
        if: ${{ always() }}
        run: |
          set -x -e -u -o pipefail
          sudo rm -rf ptrace_scope.bk
          sudo cp /proc/sys/kernel/yama/ptrace_scope ptrace_scope.bk
          cat ptrace_scope.bk
          echo "0" |sudo tee /proc/sys/kernel/yama/ptrace_scope
      - name: Run Torch XPU Distributed UT
        run: |
          set -x -e -o pipefail
          source activate xpu_op_${ZE_AFFINITY_MASK}
          pip install pytest pytest-timeout
          mkdir -p ut_log/xpu_distributed
          cd ../pytorch/third_party/torch-xpu-ops/test/xpu
          XCCL_ENABLE=$(python -c "import torch;print(torch.distributed.is_xccl_available())")
          if [[ "${XCCL_ENABLE,,}" == 'false' ]] || [[ "${XCCL_ENABLE}" == '0' ]]; then
            echo -e "[ERROR] XCCL is not enabled"
            exit 1
          fi
          timeout 1800 python run_distributed.py \
            2>${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test_error.log | \
            tee ${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test.log
      - name: Reset Ptrace_scope
        if: ${{ always() }}
        run: |
          if [ -f ptrace_scope.bk ]; then
            sudo cp ptrace_scope.bk /proc/sys/kernel/yama/ptrace_scope
          fi
      - name: Upload Inductor XPU UT Log
        if: ${{ ! cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-XPU-UT-Data-${{ github.event.pull_request.number || github.sha }}-xpu_distributed
          path: ${{ github.workspace }}/ut_log

  distributed_ut_test_results_check:
    needs: distributed_ut_test
    runs-on: ubuntu-22.04
    timeout-minutes: 30
    env:
      GH_TOKEN: ${{ github.token }}
      ut_skip_issue: 1624
    steps:
      - name: Set the UT name
        run: |
          echo "UT_NAME=$(echo ${{ inputs.ut }} |sed 's/,/-/g')" |tee -a "${GITHUB_OUTPUT}" >> "${GITHUB_ENV}"
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Download XPU UT Logs
        uses: actions/download-artifact@v4
        with:
          name: Inductor-XPU-UT-Data-${{ github.event.pull_request.number || github.sha }}-xpu_distributed
          path: ${{ github.workspace }}/ut_log
      - name: Check UT Results
        shell: bash
        run: |
          repo="${{ github.repository }}"
          function contains() {
              contains_status="echo 'Start $2 ...'"
              {
                [[ $1 =~ (^|,)$2($|,) ]]
              } || {
                echo "[Warning] $2 is not suppotted type! Skipped!"
                contains_status="continue"
              }
          }
          set -xe
          echo "UT_NAME=$(echo ${{ inputs.ut }} |sed 's/,/-/g')" |tee -a "${GITHUB_OUTPUT}" >> "${GITHUB_ENV}"
          cd ${{ github.workspace }}/ut_log/xpu_distributed
          gh --repo $repo issue view $ut_skip_issue --json body -q .body | sed '/^$/d' > Known_issue.log
          gh api "repos/${{ github.repository }}/issues?labels=skipped" \
          --jq '.[] | select(.pull_request == null) | "Issue #\(.number): \(.title)\n\(.body)\n"' \
          > issues.log
          awk '/Cases:/ {flag=1; next} /^\|\||^$/ {flag=0} flag' issues.log | grep -Eo 'test[^[:space:]]+( \|\| [^[:space:]]+)?' | sed 's/ *|| */ /g' | sort -u > issues_temp.log
          awk '$2 == "op_ut" {print $1}' issues_temp.log > issues_op_ut.log
          cat issues_temp.log | awk '{print $1}' >> Known_issue.log
          awk -F'::' '{print $1}' issues_op_ut.log | sort -u | paste -sd ',' >> Known_issue.log
          cp ${{ github.workspace }}/.github/scripts/ut_result_check.sh ./
          bash ut_result_check.sh 'xpu_distributed'
      - name: Upload Inductor XPU UT Log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-XPU-UT-Data-${{ github.event.pull_request.number || github.sha }}-xpu_distributed-checked
          path: ${{ github.workspace }}/ut_log
