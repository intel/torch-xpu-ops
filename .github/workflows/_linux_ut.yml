name: Linux UT Test

on:
  workflow_call:
    inputs:
      pytorch:
        required: false
        type: string
        default: 'main'
        description: Pytorch branch/commit
      keep_torch_xpu_ops:
        required: false
        type: string
        default: 'false'
        description: Keep torch-xpu-ops pin. `true` means use pined commit
      triton:
        required: false
        type: string
        default: ''
        description: Triton commit. Use pytorch pined commit by default
      ut:
        required: true
        type: string
        default: ''
        description: UT scope. `op_regression,op_regression_dev1,op_transformers,op_extended,op_ut,torch_xpu` Delimiter is comma
      python:
        required: false
        type: string
        default: '3.10'
        description: Python version
      runner:
        required: true
        type: string
        default: 'linux.idc.xpu'
        description: Runner label
      driver:
        required: false
        type: string
        default: 'lts'
        description: Driver lts/rolling

permissions: read-all

jobs:
  ut_test:
    runs-on: ${{ inputs.runner }} 
    if: ${{ inputs.ut != 'xpu_distributed' }}
    timeout-minutes: 900
    env:
      GH_TOKEN: ${{ github.token }}
      NEOReadDebugKeys: ${{ inputs.driver == 'rolling' && '1' || '0' }}
      DisableScratchPages: ${{ inputs.driver == 'rolling' && '1' || '0' }}
      ut_skip_issue: 1624
    steps:
      - name: Prepare Env
        run: |
          # Cleanup workspace
          rm -rf ${{ github.workspace }}/*
          which conda && conda clean -ay
          conda remove --all -y -n xpu_op_${ZE_AFFINITY_MASK} || \
                rm -rf $(dirname ${CONDA_EXE})/../envs/xpu_op_${ZE_AFFINITY_MASK}
          conda create -n xpu_op_${ZE_AFFINITY_MASK} python=${{ inputs.python }} cmake ninja -y
      - name: Checkout Torch-xpu-ops
        uses: actions/checkout@v4
        with:
          path: torch-xpu-ops
      - name: Download Pytorch Wheel
        if: ${{ inputs.pytorch != 'nightly_wheel' }}
        uses: actions/download-artifact@v4
        with:
          name: Torch-XPU-Wheel-${{ github.event.pull_request.number || github.sha }}
          path: ${{ github.workspace }}
      - name: Prepare Pytorch
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            pip install --force-reinstall ${{ github.workspace }}/torch*.whl
          else
            pip install torch torchvision torchaudio --pre --index-url https://download.pytorch.org/whl/nightly/xpu
          fi
          TORCH_COMMIT_ID=$(python -c 'import torch; print(torch.version.git_version)')
          rm -rf ./pytorch
          git clone https://github.com/pytorch/pytorch ./pytorch
          cd ./pytorch
          git checkout $TORCH_COMMIT_ID
          pip install -r .ci/docker/requirements-ci.txt
      - name: Prepare Torch-xpu-ops
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ./pytorch
          rm -rf third_party/torch-xpu-ops
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ] && [ "${{ inputs.keep_torch_xpu_ops }}" == "false" ]; then
            cp -r ${{ github.workspace }}/torch-xpu-ops third_party/torch-xpu-ops
            cd third_party/torch-xpu-ops
          else
            TORCH_XPU_OPS_COMMIT=$(cat third_party/xpu.txt)
            git clone https://github.com/intel/torch-xpu-ops.git third_party/torch-xpu-ops
            cd third_party/torch-xpu-ops
            git checkout $TORCH_XPU_OPS_COMMIT
          fi
          git show -s
          # Apply extra patches for pytorch
          cd ${{ github.workspace }}/pytorch
          pip install requests
          python third_party/torch-xpu-ops/.github/scripts/apply_torch_pr.py
      - name: Deps Installation
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ./pytorch
          TRITON_REPO="https://github.com/intel/intel-xpu-backend-for-triton"
          if [ -z ${{ inputs.triton }} ]; then
            TRITON_COMMIT_ID="$(cat .ci/docker/ci_commit_pins/triton-xpu.txt)"
          else
            TRITON_COMMIT_ID="${{ inputs.triton }}"
          fi
          echo ${TRITON_REPO}@${TRITON_COMMIT_ID}
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            # Triton
            pip install --force-reinstall "git+${TRITON_REPO}@${TRITON_COMMIT_ID}#subdirectory=python"
            # Torchvision
            rm -rf xpu-vision
            git clone https://github.com/pytorch/vision xpu-vision
            cd xpu-vision
            git show -s
            python setup.py install
          fi
          pip install pytest pytest-timeout
      - name: Torch Config
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          python -c "import torch; print(torch.__config__.show())"
          python -c "import torch; print(torch.__config__.parallel_info())"
          python -c "import torch; print(torch.__config__.torch.xpu.device_count())"
          python -c "import triton; print(triton.__version__)"
          python pytorch/torch/utils/collect_env.py
          xpu-smi discovery
          rm -rf /tmp/torchinductor_*
          rm -rf ~/.triton/cache
      - name: Run XPU OP Regression
        if: contains(inputs.ut, 'op_regression')
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}  
          mkdir -p ut_log/op_regression
          cd pytorch/third_party/torch-xpu-ops/test/regressions
          timeout 3600 pytest --timeout 600 -v \
            --junit-xml=${{ github.workspace }}/ut_log/op_regression.xml \
            2>${{ github.workspace }}/ut_log/op_regression/op_regression_test_error.log | \
            tee ${{ github.workspace }}/ut_log/op_regression/op_regression_test.log
      - name: Run XPU OP Regressions test on device 1
        if: contains(inputs.ut, 'op_regression_dev1')
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          mkdir -p ut_log/op_regression_dev1
          unset ZE_AFFINITY_MASK
          cd pytorch/third_party/torch-xpu-ops/test/regressions
          timeout 3600 pytest --timeout 600 -v test_operation_on_device_1.py \
            --junit-xml=${{ github.workspace }}/ut_log/op_regression_dev1.xml \
            2>${{ github.workspace }}/ut_log/op_regression_dev1/op_regression_dev1_test_error.log | \
            tee ${{ github.workspace }}/ut_log/op_regression_dev1/op_regression_dev1_test.log
      - name: Run XPU Transformers UT
        if: contains(inputs.ut, 'op_transformers')
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          mkdir -p ut_log/op_transformers
          export PYTORCH_TEST_WITH_SLOW=1
          cd pytorch
          timeout 3600 pytest --timeout 600 -v test/test_transformers.py -k xpu \
            --junit-xml=${{ github.workspace }}/ut_log/op_transformers.xml \
            2>${{ github.workspace }}/ut_log/op_transformers/op_transformers_test_error.log | \
            tee ${{ github.workspace }}/ut_log/op_transformers/op_transformers_test.log
      - name: Run XPU OP Extended UT
        if: contains(inputs.ut, 'op_extended')
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          mkdir -p ut_log/op_extended
          export PYTORCH_TEST_WITH_SLOW=1
          cd pytorch/third_party/torch-xpu-ops/test/xpu/extended/
          timeout 10000 python run_test_with_skip.py \
            2>${{ github.workspace }}/ut_log/op_extended/op_extended_test_error.log | \
            tee ${{ github.workspace }}/ut_log/op_extended/op_extended_test.log
          cp op_extended.xml ${{ github.workspace }}/ut_log
      - name: Run XPU OP UT
        if: contains(inputs.ut, 'op_ut')
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          mkdir -p ut_log/op_ut
          export PYTORCH_ENABLE_XPU_FALLBACK=1
          export PYTORCH_TEST_WITH_SLOW=1
          cd pytorch/third_party/torch-xpu-ops/test/xpu
          timeout 10000 python run_test_with_skip.py \
            2>${{ github.workspace }}/ut_log/op_ut/op_ut_with_skip_test_error.log | \
            tee ${{ github.workspace }}/ut_log/op_ut/op_ut_with_skip_test.log
          cp *.xml ${{ github.workspace }}/ut_log
          find op_ut_with_skip_nn op_ut_with_skip_quantization/core -type f -exec sh -c '
              dir_path=$(dirname "$1");
              case "$dir_path" in
                  *"op_ut_with_skip_quantization/core"*)
                      dir_name="op_ut_with_skip_quantization_core";;
                  *)
                      dir_name=$(basename "$dir_path");;
              esac;
              mv "$1" "$dir_path/${dir_name}_$(basename "$1")"
          ' _ {} \;
          cp op_ut_with_skip_nn/*.xml ${{ github.workspace }}/ut_log
          cp op_ut_with_skip_quantization/core/*.xml ${{ github.workspace }}/ut_log
          # Cases run with a on-demand white list, since some suites are too
          # slow to go through all operators on CPU. So add cases on-demand
          # when XPU implementatoin is done.
          # test_foreach, test_decomp
          timeout 10000 python run_test_with_only.py \
            2>${{ github.workspace }}/ut_log/op_ut/op_ut_with_only_test_error.log | \
            tee ${{ github.workspace }}/ut_log/op_ut/op_ut_with_only_test.log
          cp op_ut_with_only.xml ${{ github.workspace }}/ut_log
      - name: Run Torch XPU UT
        if: contains(inputs.ut, 'torch_xpu')
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          mkdir -p ut_log/torch_xpu
          cd pytorch
          TEST_REPORTS_DIR=$(pwd)/test/test-reports
          rm -rf "$TEST_REPORTS_DIR" && mkdir -p "$TEST_REPORTS_DIR"
          # Run Pytorch XPU binary UT
          for xpu_case in build/bin/*{xpu,sycl}*; do
            if [[ "$xpu_case" != *"*"* && "$xpu_case" != *.so && "$xpu_case" != *.a ]]; then
              case_name=$(basename "$xpu_case")
              echo "Testing ${case_name} ..."
              "$xpu_case" --gtest_output=xml:"$TEST_REPORTS_DIR"/"$case_name".xml \
                2>${{ github.workspace }}/ut_log/torch_xpu/binary_ut_torch_xpu_${case_name}_test_error.log | \
                tee ${{ github.workspace }}/ut_log/torch_xpu/binary_ut_torch_xpu_${case_name}_test.log
            fi
          done
          # Run Pytorch XPU python UT
          export PYTORCH_TEST_WITH_SLOW=1
          export PYTORCH_TESTING_DEVICE_ONLY_FOR="xpu"

          test_cmd="python test/run_test.py --include "
          # All Inductor UT under test/inductor
          for test in $(ls test/inductor | grep test);
          do 
              test_cmd="${test_cmd} inductor/$test";
          done
          # All xpu ut under test/xpu
          for test in $(ls test/xpu | grep test);
          do 
              test_cmd="${test_cmd} xpu/$test";
          done
          if [ -f "test/test_xpu.py" ]; then
            test_cmd="${test_cmd} test_xpu.py"
          fi
          eval $test_cmd 2>${{ github.workspace }}/ut_log/torch_xpu/torch_xpu_test_error.log | \
            tee ${{ github.workspace }}/ut_log/torch_xpu/torch_xpu_test.log
      - name: Run Torch XPU Profile UT
        if: ${{ inputs.driver == 'rolling' && contains(inputs.ut, 'xpu_profiling') }} 
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd pytorch/third_party/torch-xpu-ops
          mkdir -p ${{ github.workspace }}/ut_log/profile_test
          # RN50 Test
          PROFILE=1 python -u test/profiling/rn50.py -a resnet50 --dummy ./ --num-iterations 20 --xpu 0
          cp profiling.fp32.train.pt ${{ github.workspace }}/ut_log/profile_test

          # All Issue Reproduce UT
          mkdir -p ${{ github.workspace }}/ut_log/profile_test/issue_reproduce
          python -u test/profiling/correlation_id_mixed.py | \
            tee ${{ github.workspace }}/ut_log/profile_test/issue_reproduce/correlation_id_mixed.log
          python -u test/profiling/reproducer.missing.gpu.kernel.time.py | \
            tee ${{ github.workspace }}/ut_log/profile_test/issue_reproduce/reproducer.missing.gpu.kernel.time.log
          python -u test/profiling/time_precision_in_profile.py | \
            tee ${{ github.workspace }}/ut_log/profile_test/issue_reproduce/time_precision_in_profile.log
          python -u test/profiling/profile_partial_runtime_ops.py | \
            tee ${{ github.workspace }}/ut_log/profile_test/issue_reproduce/profile_partial_runtime_ops.log
          python -u test/profiling/triton_xpu_ops_time.py | \
            tee ${{ github.workspace }}/ut_log/profile_test/issue_reproduce/triton_xpu_ops_time.log

          # All xpu ut under test/profiler
          cd ${{ github.workspace }}/pytorch/test/profiler
          python -m pytest --timeout 600 -vs test_cpp_thread.py | \
            tee ${{ github.workspace }}/ut_log/profile_test/test_cpp_thread.log
          python -m pytest --timeout 600 -vs test_execution_trace.py | \
            tee ${{ github.workspace }}/ut_log/profile_test/test_execution_trace.log
          python -m pytest --timeout 600 -vs test_memory_profiler.py | \
            tee ${{ github.workspace }}/ut_log/profile_test/test_memory_profiler.log
          python -m pytest --timeout 600 -vs test_profiler_tree.py | \
            tee ${{ github.workspace }}/ut_log/profile_test/test_profiler_tree.log
      - name: UT Test Results Summary
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          pip install junitparser
          cd torch-xpu-ops
          python .github/scripts/check-ut.py ${{ github.workspace }}/ut_log/*.xml >> $GITHUB_STEP_SUMMARY || true
      - name: UT Test Results Check
        shell: bash
        run: |
          repo="${{ github.repository }}"
          function contains() {
              contains_status="echo 'Start $2 ...'"
              {
                [[ $1 =~ (^|,)$2($|,) ]]
              } || {
                echo "[Warning] $2 is not suppotted type! Skipped!"
                contains_status="continue"
              }
          }
          set -xe
          echo "UT_NAME=$(echo ${{ inputs.ut }} |sed 's/,/-/g')" |tee -a "${GITHUB_OUTPUT}" >> "${GITHUB_ENV}"
          for ut_suite in $(echo ${{ inputs.ut }} |sed 's/,/ /g')
          do
            contains "op_regression,op_regression_dev1,op_transformers,op_extended,op_ut,torch_xpu" $ut_suite
            $contains_status
            cd ${{ github.workspace }}/ut_log/${ut_suite}
            gh --repo $repo issue view $ut_skip_issue --json body -q .body | sed '/^$/d' > Known_issue.log
            cp ${{ github.workspace }}/torch-xpu-ops/.github/scripts/ut_result_check.sh ./
            bash ut_result_check.sh ${ut_suite}
          done
      - name: Upload Inductor XPU UT Log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-XPU-UT-Data-${{ github.event.pull_request.number || github.sha }}-${{ env.UT_NAME }}
          path: ${{ github.workspace }}/ut_log
  
  distributed_ut_test:
    runs-on: pvc_e2e
    if: contains(inputs.ut, 'xpu_distributed')
    timeout-minutes: 900
    env:
      GH_TOKEN: ${{ github.token }}
      NEOReadDebugKeys: ${{ inputs.driver == 'rolling' && '1' || '0' }}
      DisableScratchPages: ${{ inputs.driver == 'rolling' && '1' || '0' }}
      ut_skip_issue: 1624
    steps:
      - name: Prepare Env
        run: |
          # Cleanup workspace
          rm -rf ${{ github.workspace }}/*
          which conda && conda clean -ay
          conda remove --all -y -n xpu_op_${ZE_AFFINITY_MASK} || \
                rm -rf $(dirname ${CONDA_EXE})/../envs/xpu_op_${ZE_AFFINITY_MASK}
          conda create -n xpu_op_${ZE_AFFINITY_MASK} python=${{ inputs.python }} cmake ninja -y
      - name: Checkout Torch-xpu-ops
        uses: actions/checkout@v4
        with:
          path: torch-xpu-ops
      - name: Download Pytorch Wheel
        if: ${{ inputs.pytorch != 'nightly_wheel' }}
        uses: actions/download-artifact@v4
        with:
          name: Torch-XPU-Wheel-${{ github.event.pull_request.number || github.sha }}
          path: ${{ github.workspace }}
      - name: Prepare Pytorch
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            pip install --force-reinstall ${{ github.workspace }}/torch*.whl
          else
            pip install torch torchvision torchaudio --pre --index-url https://download.pytorch.org/whl/nightly/xpu
          fi
          TORCH_COMMIT_ID=$(python -c 'import torch; print(torch.version.git_version)')
          rm -rf ./pytorch
          git clone https://github.com/pytorch/pytorch ./pytorch
          cd ./pytorch
          git checkout $TORCH_COMMIT_ID
          pip install -r .ci/docker/requirements-ci.txt
      - name: Prepare Torch-xpu-ops
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ./pytorch
          rm -rf third_party/torch-xpu-ops
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ] && [ "${{ inputs.keep_torch_xpu_ops }}" == "false" ]; then
            cp -r ${{ github.workspace }}/torch-xpu-ops third_party/torch-xpu-ops
            cd third_party/torch-xpu-ops
          else
            TORCH_XPU_OPS_COMMIT=$(cat third_party/xpu.txt)
            git clone https://github.com/intel/torch-xpu-ops.git third_party/torch-xpu-ops
            cd third_party/torch-xpu-ops
            git checkout $TORCH_XPU_OPS_COMMIT
          fi
          git show -s
          # Apply extra patches for pytorch
          cd ${{ github.workspace }}/pytorch
          pip install requests
          python third_party/torch-xpu-ops/.github/scripts/apply_torch_pr.py
      - name: Deps Installation
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ./pytorch
          TRITON_REPO="https://github.com/intel/intel-xpu-backend-for-triton"
          if [ -z ${{ inputs.triton }} ]; then
            TRITON_COMMIT_ID="$(cat .ci/docker/ci_commit_pins/triton-xpu.txt)"
          else
            TRITON_COMMIT_ID="${{ inputs.triton }}"
          fi
          echo ${TRITON_REPO}@${TRITON_COMMIT_ID}
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            # Triton
            pip install --force-reinstall "git+${TRITON_REPO}@${TRITON_COMMIT_ID}#subdirectory=python"
            # Torchvision
            rm -rf xpu-vision
            git clone https://github.com/pytorch/vision xpu-vision
            cd xpu-vision
            git show -s
            python setup.py install
          fi
          pip install pytest pytest-timeout
      - name: Torch Config
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          python -c "import torch; print(torch.__config__.show())"
          python -c "import torch; print(torch.__config__.parallel_info())"
          python -c "import torch; print(torch.__config__.torch.xpu.device_count())"
          python -c "import triton; print(triton.__version__)"
          python pytorch/torch/utils/collect_env.py
          xpu-smi discovery
          rm -rf /tmp/torchinductor_*
          rm -rf ~/.triton/cache
      - name: Set Ptrace_scope
        if: ${{ always() }}
        run: |
          sudo cp /proc/sys/kernel/yama/ptrace_scope ptrace_scope.bk
          sudo echo "0"|sudo tee /proc/sys/kernel/yama/ptrace_scope
      - name: Run Torch XPU Distributed UT
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          mkdir -p ut_log/xpu_distributed
          cd pytorch/third_party/torch-xpu-ops/test/xpu
          XCCL_EANBLE=$(python -c "import torch;print(torch.distributed.is_xccl_available())")
          if [[ "${XCCL_ENABLE}}" == 'False' ]]; then
            echo -e "[ERROR] XCCL is not enabled"
            exit 1
          fi
          timeout 10000 python run_distributed.py \
            2>${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test_error.log | \
            tee ${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test.log
      - name: Reset Ptrace_scope
        if: ${{ always() }}
        run: |
          sudo cp ptrace_scope.bk /proc/sys/kernel/yama/ptrace_scope
      - name: UT Test Results Check
        shell: bash
        run: |
          repo="${{ github.repository }}"
          function contains() {
              contains_status="echo 'Start $2 ...'"
              {
                [[ $1 =~ (^|,)$2($|,) ]]
              } || {
                echo "[Warning] $2 is not suppotted type! Skipped!"
                contains_status="continue"
              }
          }
          set -xe
          echo "UT_NAME=$(echo ${{ inputs.ut }} |sed 's/,/-/g')" |tee -a "${GITHUB_OUTPUT}" >> "${GITHUB_ENV}"
          cd ${{ github.workspace }}/ut_log/xpu_distributed
          gh --repo $repo issue view $ut_skip_issue --json body -q .body | sed '/^$/d' > Known_issue.log
          cp ${{ github.workspace }}/torch-xpu-ops/.github/scripts/ut_result_check.sh ./
          bash ut_result_check.sh 'xpu_distributed'
      - name: Upload Inductor XPU UT Log
        if: ${{ ! cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-XPU-UT-Data-${{ github.event.pull_request.number || github.sha }}-xpu_distributed
          path: ${{ github.workspace }}/ut_log
