name: Linux OP Benchmark Test

on:
  workflow_call:
    inputs:
      runner:
        required: true
        type: string
        default: 'pvc_rolling'
        description: Runner label
      test_type:
        type: string
        default: 'build-from-source'
        description: Build from source or install nightly wheel
      pytorch:
        type: string
        default: 'main'
        description: Pytorch main by default, or 'commit/branch', or 'repo@commit/repo@branch'
      oneapi:
        type: string
        default: 'installed'
        description: Installed oneAPI DLE on host by default, fill offline.sh url if needed
      python:
        type: string
        default: '3.10'
        description: Python version

permissions: read-all

jobs:
  get_op_runner:
    runs-on: ${{ inputs.runner }}
    outputs:
      test_host: ${{ steps.runner-info.outputs.test_host }}
      test_user: ${{ steps.runner-info.outputs.test_user }}
      test_group: ${{ steps.runner-info.outputs.test_group }}
    steps:
      - name: Get runner info
        id: runner-info
        run: |
          # get test runner
          echo "test_host=${RUNNER_NAME}" |tee -a ${GITHUB_OUTPUT}
          echo "test_user=$(id -u)" |tee -a ${GITHUB_OUTPUT}
          echo "test_group=$(getent group render |cut -d: -f3)" |tee -a ${GITHUB_OUTPUT}
          # show host info
          cat /etc/os-release
          uname -a
          source /opt/intel/oneapi/setvars.sh
          sycl-ls
          dpkg -l |grep -E 'libigc-dev|libze-dev|level-zero-dev'
      - name: Cleanup workspace
        if: ${{ always() }}
        run: |
          # clean docker cache
          docker stop $(docker ps -aq) || true
          docker system prune -af || true
          # clean files
          ls -al
          sudo find ./ |grep -v "^\./$" |xargs sudo rm -rf
          sudo rm -rf ${RUNNER_TEMP} ${RUNNER_TOOL_CACHE}

  op_benchmark_test:
    needs: get_op_runner
    runs-on: ${{ needs.get_op_runner.outputs.test_host }}
    permissions: 
      issues: write
    timeout-minutes: 900
    container:
      image: mengfeili/intel-pvc-driver:1146-1136
      volumes:
        - ${{ github.workspace }}:${{ github.workspace }}
      options: --device=/dev/mem --device=/dev/dri --group-add video --privileged --shm-size=8g
              -u ${{ needs.get_op_runner.outputs.test_user }}:${{ needs.get_op_runner.outputs.test_group }}
      env:
        AGENT_TOOLSDIRECTORY: /opt/_tools
        GH_TOKEN: ${{ github.token }}
        HUGGING_FACE_HUB_TOKEN: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
        REFERENCE_ISSUE: 1689
    defaults:
      run:
        shell: bash -xe {0}
    steps:
      - name: Setup python-${{ inputs.python }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python }}
      - name: Check runner
        run: |
          ls -al
          find ./ |grep -v "^\./$" |xargs rm -rf
          hostname && whoami && id
          clinfo --list
          gcc -v && g++ -v
          which python && which pip
          python -V
          pip install -U pip wheel setuptools
          pip list
          uname -a
          dpkg -l |grep -E 'libigc-dev|libze-dev|level-zero-dev'
          pip install pandas psutil scipy requests
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Install oneAPI DLE
        if: ${{ inputs.oneapi != 'installed' }}
        run: |
          rm -rf ~/intel ~/.intel
          wget -q -O oneapi.sh "${{ inputs.oneapi }}"
          bash oneapi.sh -a -s --eula accept --action install --install-dir ${HOME}/intel/oneapi
          echo "XPU_ONEAPI_PATH=${HOME}/intel/oneapi" >> ${GITHUB_ENV}
      - name: Download Pytorch wheel
        if: ${{ ! contains(inputs.test_type, 'wheel') }}
        uses: actions/download-artifact@v4
        with:
          pattern: Torch-XPU-Wheel-*
      - name: Prepare Stock Pytorch
        run: |
          # install pytorch
          if [ $(echo "${{ inputs.pytorch }}" |grep -w "release_wheel" |wc -l) -ne 0 ];then
            pip install torch torchvision torchaudio --pre --index-url https://download.pytorch.org/whl/xpu
          elif [ $(echo "${{ inputs.pytorch }}" |grep -w "test_wheel" |wc -l) -ne 0 ];then
            pip install torch torchvision torchaudio --pre --index-url https://download.pytorch.org/whl/test/xpu
          elif [ $(echo "${{ inputs.pytorch }}" |grep -w "nightly_wheel" |wc -l) -ne 0 ];then
            pip install torch torchvision torchaudio --pre --index-url https://download.pytorch.org/whl/nightly/xpu
          else
            pip install --force-reinstall ${{ github.workspace }}/*.whl
          fi
      - name: Torch Config
        run: |
          printenv
          python -c "import torch; print(torch.__config__.show())"
          python -c "import torch; print(torch.__config__.parallel_info())"
          python -c "import torch; print(torch.__config__.torch.xpu.device_count())"
          python -c "import torchvision; print(torchvision.__version__)"
          python -c "import torchaudio; print(torchaudio.__version__)"
          python -c "import triton; print(triton.__version__)"
          pip list |grep -E 'torch|intel'

      - name: Run Torch XPU Op Benchmark
        run: |
          mkdir -p ${{ github.workspace }}/op_benchmark
          cd test/microbench
          filename=$(find -- *.py)
          for i in $filename
          do
            python ${i%.*}.py > ${{ github.workspace }}/op_benchmark/${i%.*}.log
          done
          # Summary forward op time
          bash ${{ github.workspace }}/.github/scripts/microbench_summary.sh ${{ github.workspace }}/op_benchmark ${{ github.workspace }}/op_benchmark/forward_op_summary.csv
          # Summary backward op time
          bash ${{ github.workspace }}/.github/scripts/microbench_summary.sh ${{ github.workspace }}/op_benchmark ${{ github.workspace }}/op_benchmark/backward_op_summary.csv True
      - name: Download OP Baseline
        continue-on-error: true
        id: reference_id
        run: |
          REFERENCE_RUN_ID="$(gh --repo ${GITHUB_REPOSITORY} issue view ${REFERENCE_ISSUE} \
            --json body -q .body |grep "Inductor-XPU-OP-Benchmark-Data" |sed 's/.*: *//')"
          gh --repo ${GITHUB_REPOSITORY} run download ${REFERENCE_RUN_ID} -p "Inductor-XPU-OP-Benchmark-Data-*"
          rm -rf ${GITHUB_WORKSPACE:-"/tmp"}/reference
          mkdir ${GITHUB_WORKSPACE:-"/tmp"}/reference
          mv Inductor-XPU-OP-Benchmark-Data-*/* ${GITHUB_WORKSPACE:-"/tmp"}/reference
          mkdir ${{ github.workspace }}/baseline
          if [[ -f "${GITHUB_WORKSPACE:-"/tmp"}/reference/new_baseline/baseline_forward_op_summary.csv" ]]; then
            cp ${GITHUB_WORKSPACE:-"/tmp"}/reference/new_baseline/baseline_forward_op_summary.csv ${{ github.workspace }}/baseline
            cp ${GITHUB_WORKSPACE:-"/tmp"}/reference/new_baseline/baseline_backward_op_summary.csv ${{ github.workspace }}/baseline
          else
            cp ${GITHUB_WORKSPACE:-"/tmp"}/reference/forward_op_summary.csv ${{ github.workspace }}/baseline/baseline_forward_op_summary.csv
            cp ${GITHUB_WORKSPACE:-"/tmp"}/reference/backward_op_summary.csv ${{ github.workspace }}/baseline/baseline_backward_op_summary.csv
          fi
      - name: Check the OP Regression
        run: |
          pip install tabulate
          # Compare forward op
          python ${{ github.workspace }}/.github/scripts/op_perf_comparison.py --xpu_file ${{ github.workspace }}/op_benchmark/forward_op_summary.csv --baseline_file ${{ github.workspace }}/baseline/baseline_forward_op_summary.csv
          # Compare backward op
          python ${{ github.workspace }}/.github/scripts/op_perf_comparison.py --xpu_file ${{ github.workspace }}/op_benchmark/backward_op_summary.csv --baseline_file ${{ github.workspace }}/baseline/baseline_backward_op_summary.csv
      - name: Update OP Baseline
        run: |
          mkdir ${{ github.workspace }}/new_baseline
          cp ${{ github.workspace }}/baseline/baseline*.csv ${{ github.workspace }}/new_baseline
          # Update forward op
          python ${{ github.workspace }}/.github/scripts/op_calculate_best_perf.py --xpu ${{ github.workspace }}/op_benchmark/forward_op_summary.csv --baseline ${{ github.workspace }}/new_baseline/baseline_forward_op_summary.csv -r
          # Update backward op
          python ${{ github.workspace }}/.github/scripts/op_calculate_best_perf.py --xpu ${{ github.workspace }}/op_benchmark/backward_op_summary.csv --baseline ${{ github.workspace }}/new_baseline/baseline_backward_op_summary.csv -r
          cp -r ${{ github.workspace }}/new_baseline ${{ github.workspace }}/op_benchmark
      - name: Upload Inductor XPU OP benchmark Log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-XPU-OP-Benchmark-Data-${{ github.event.pull_request.number || github.sha }}
          path: ${{ github.workspace }}/op_benchmark
      - name: Upload Reference Run ID
        run: |
          gh --repo ${GITHUB_REPOSITORY} issue view ${REFERENCE_ISSUE} --json body -q .body | \
            sed "s/Inductor-XPU-OP-Benchmark-Data:.*/Inductor-XPU-OP-Benchmark-Data: ${GITHUB_RUN_ID}/" | sed '/^$/d' > new_body.txt
          gh --repo ${GITHUB_REPOSITORY} issue edit ${REFERENCE_ISSUE} --body-file new_body.txt
