name: Linux OP Benchmark Test

on:
  workflow_call:
    inputs:
      pytorch:
        required: false
        type: string
        default: 'main'
        description: Pytorch branch/commit
      keep_torch_xpu_ops:
        required: false
        type: string
        default: 'false'
        description: Keep torch-xpu-ops pin. `true` means use pined commit
      triton:
        required: false
        type: string
        default: ''
        description: Triton commit. Use pytorch pined commit by default
      abi:
        required: false
        type: string
        default: '1'
        description: ABI version. Default abi as 1.
      python:
        required: false
        type: string
        default: '3.10'
        description: Python version
      runner:
        required: true
        type: string
        default: 'linux.idc.xpu'
        description: Runner label
      driver:
        required: false
        type: string
        default: 'lts'
        description: Driver lts/rolling

permissions: read-all

jobs:
  benchmark_test:
    runs-on: ${{ inputs.runner }} 
    if: ${{ inputs.ut != 'xpu_distributed' }}
    timeout-minutes: 900
    env:
      NEOReadDebugKeys: ${{ inputs.driver == 'rolling' && '1' || '0' }}
      DisableScratchPages: ${{ inputs.driver == 'rolling' && '1' || '0' }}
    steps:
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Prepare Stock Pytorch
        run: |
          pwd
          which conda && conda clean -ay
          conda remove --all -y -n xpu_op_${ZE_AFFINITY_MASK} || \
                rm -rf $(dirname ${CONDA_EXE})/../envs/xpu_op_${ZE_AFFINITY_MASK}
          conda create -n xpu_op_${ZE_AFFINITY_MASK} python=${{ inputs.python }} cmake ninja -y
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ../ && rm -rf pytorch
          pip install requests
          git clone https://github.com/pytorch/pytorch pytorch
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            cd pytorch && git checkout $(echo ${{ inputs.pytorch }})
            # apply PRs for stock pytorch
            python ../torch-xpu-ops/.github/scripts/apply_torch_pr.py
            git status && git show -s
            git submodule sync && git submodule update --init --recursive
            if [[ ${{ inputs.keep_torch_xpu_ops }} == 'true' ]]; then
              echo "Don't replace torch-xpu-ops!"
            else
              rm -rf third_party/torch-xpu-ops && cp -r ../torch-xpu-ops third_party/
              # Workaround for torch-xpu-ops ci test
              sed -i "s/checkout --quiet \${TORCH_XPU_OPS_COMMIT}/log -n 1/g" caffe2/CMakeLists.txt
            fi
          fi
      - name: Triton Installation
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ../pytorch
          TRITON_REPO="https://github.com/intel/intel-xpu-backend-for-triton"
          if [ -z ${{ inputs.triton }} ]; then
            TRITON_COMMIT_ID="$(<.ci/docker/ci_commit_pins/triton-xpu.txt)"
          else
            TRITON_COMMIT_ID="${{ inputs.triton }}"
          fi
          echo ${TRITON_REPO}@${TRITON_COMMIT_ID}
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            pip install --force-reinstall "git+${TRITON_REPO}@${TRITON_COMMIT_ID}#subdirectory=python"
          fi
      - name: Download Pytorch wheel
        if: ${{ inputs.pytorch != 'nightly_wheel' }}
        uses: actions/download-artifact@v4
        with:
          name: Torch-XPU-Wheel-${{ github.event.pull_request.number || github.sha }}-${{ inputs.abi }}
          path: ${{ github.workspace }}
      - name: Install Pytorch XPU
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          source .github/scripts/env.sh ${{ inputs.pytorch }}
          pip install mkl-static==2025.0.1 mkl-include==2025.0.1
          if [[ ${{ inputs.abi }} == '0' ]]; then
            export _GLIBCXX_USE_CXX11_ABI=0
          else
            export _GLIBCXX_USE_CXX11_ABI=1
          fi
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            cd ../pytorch
            export CMAKE_PREFIX_PATH=${CMAKE_PREFIX_PATH}:${CONDA_PREFIX:-"$(dirname $(which conda))/../"}
            pip install -r requirements.txt
            pip install --force-reinstall ${{ github.workspace }}/torch*.whl
            git clone https://github.com/pytorch/vision && cd vision && python setup.py install && cd ..
          else
            pip install torch torchvision torchaudio --pre --index-url https://download.pytorch.org/whl/nightly/xpu
            TORCH_COMMIT_ID=$(python -c 'import torch; print(torch.version.git_version)')
            cd ../pytorch
            git reset --hard && git checkout ${TORCH_COMMIT_ID}
            TORCH_XPU_OPS_COMMIT=$(<third_party/xpu.txt)
            rm -rf third_party/torch-xpu-ops
            git clone https://github.com/intel/torch-xpu-ops.git third_party/torch-xpu-ops
            cd third_party/torch-xpu-ops
            git checkout ${TORCH_XPU_OPS_COMMIT}
            cd ../..
            python third_party/torch-xpu-ops/.github/scripts/apply_torch_pr.py
          fi
          pip install -r .ci/docker/requirements-ci.txt
          pip install addict
      - name: Torch Config
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          source .github/scripts/env.sh ${{ inputs.pytorch }}
          python -c "import torch; print(torch.__config__.show())"
          python -c "import torch; print(torch.__config__.parallel_info())"
          python -c "import torch; print(torch.__config__.torch.xpu.device_count())"
          python -c "import triton; print(triton.__version__)"

          cd ..
          python pytorch/torch/utils/collect_env.py
          rm -rf /tmp/torchinductor_*
          rm -rf ~/.triton/cache
      - name: Identify pinned versions
        run: |
          cd ../pytorch
          echo "TRITON_COMMIT_ID=$(<.ci/docker/ci_commit_pins/triton-xpu.txt)" >> "${GITHUB_ENV}"
          echo "TORCHVISION_COMMIT_ID=$(<.github/ci_commit_pins/vision.txt)" >> "${GITHUB_ENV}"
          echo "TORCHBENCH_COMMIT_ID=$(<.github/ci_commit_pins/torchbench.txt)" >> "${GITHUB_ENV}"
          echo "TORCHAUDIO_COMMIT_ID=$(<.github/ci_commit_pins/audio.txt)" >> "${GITHUB_ENV}"
          echo "TRANSFORMERS_VERSION=$(<.ci/docker/ci_commit_pins/huggingface.txt)" >> "${GITHUB_ENV}"
          echo "TIMM_COMMIT_ID=$(<.ci/docker/ci_commit_pins/timm.txt)" >> "${GITHUB_ENV}"
      - name: Prepare Conda Env
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          source .github/scripts/env.sh ${{ inputs.pytorch }}
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            cd ../ && rm -rf audio && git clone --single-branch -b main https://github.com/pytorch/audio.git
            cd audio && git checkout $TORCHAUDIO_COMMIT_ID
            python setup.py bdist_wheel && pip uninstall torchaudio -y && pip install dist/*.whl
            cd ../ && rm -rf vision && git clone --single-branch -b main https://github.com/pytorch/vision.git
            cd vision && git checkout $TORCHVISION_COMMIT_ID
            python setup.py bdist_wheel && pip uninstall torchvision -y && pip install dist/*.whl
          fi
          cd ../ && python -c "import torch, torchvision, torchaudio"
          rm -rf benchmark && git clone https://github.com/pytorch/benchmark.git
          cd benchmark && git checkout 373ffb19dc470f4423a3176a4133f8f4b3cdb5bd && pip install --no-deps -r requirements.txt
          python install.py --continue_on_fail
          # deps for torchrec_dlrm
          pip install pyre_extensions
          pip install fbgemm-gpu --index-url https://download.pytorch.org/whl/nightly/cpu
          pip install torchmetrics==1.0.3
          pip install torchrec --no-deps --index-url https://download.pytorch.org/whl/nightly/cpu
          pip install --force-reinstall git+https://github.com/huggingface/transformers@${TRANSFORMERS_VERSION}
          if [ "${{ inputs.pytorch }}" != "nightly_wheel" ]; then
            cd ../ && rm -rf vision && git clone --single-branch -b main https://github.com/pytorch/vision.git
            cd vision && git checkout $TORCHVISION_COMMIT_ID
            python setup.py bdist_wheel && pip uninstall torchvision -y && pip install dist/*.whl
          fi
          # install timm without dependencies
          pip install --no-deps git+https://github.com/huggingface/pytorch-image-models@$TIMM_COMMIT_ID
          # install timm dependencies without torch and torchvision
          pip install $(curl -sSL https://raw.githubusercontent.com/huggingface/pytorch-image-models/$TIMM_COMMIT_ID/requirements.txt | grep -vE torch)
          pip install numpy==1.26.4
          pip install addict
      - name: Run OP Benchmark Test
        run: |
          cd ${{ github.workspace }}
          source .github/scripts/env.sh ${{ inputs.pytorch }}
          source activate xpu_op_${ZE_AFFINITY_MASK}
          xpu-smi discovery
          python ./tools/benchmarks/run_torchbench.py
