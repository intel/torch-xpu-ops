name: pull

on:
  pull_request:
    types:
      - opened
      - synchronize
      - reopened
      - converted_to_draft
      - ready_for_review
      - labeled
    branches:
      - main
      - release/*

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}
  cancel-in-progress: true

permissions: read-all

jobs:
  preci-lint-check:
    # Don't run on forked repos and draft PRs
    if: ${{ github.repository_owner == 'intel' }}
    name: preci-lint-check
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Run lint check
        run: |
          export ADDITIONAL_LINTRUNNER_ARGS="--skip CLANGTIDY,CLANGFORMAT,MERGE_CONFLICTLESS_CSV --all-files"
          bash .github/scripts/lintrunner.sh
      - name: Run lint check with Clang
        run: |
          sudo apt update -y && sudo apt install -y libomp-dev
          cd ../ && rm -rf pytorch
          git clone https://github.com/pytorch/pytorch pytorch
          cd pytorch && cp -r ../torch-xpu-ops third_party/
          export ADDITIONAL_LINTRUNNER_ARGS="--take CLANGTIDY,CLANGFORMAT build/xpu/**/*.* build/xpu/*.* third_party/torch-xpu-ops/src/*.* third_party/torch-xpu-ops/src/**/*.* third_party/torch-xpu-ops/src/**/**/*.* third_party/torch-xpu-ops/src/**/**/**/*.*"
          export CLANG=1
          bash third_party/torch-xpu-ops/.github/scripts/lintrunner.sh

  preci-linux-build:
    # Don't run on forked repos and draft PRs
    secrets: inherit
    if: ${{ (github.repository_owner == 'intel') && (github.event.pull_request.draft == false) }}
    name: preci-linux
    needs: preci-lint-check
    permissions:
      issues: write
    uses: ./.github/workflows/_linux_build.yml
    with:
      pytorch: main
      runner: pvc_e2e

  preci-ut:
    # Don't run on forked repos and draft PRs
    secrets: inherit
    if: ${{ (github.repository_owner == 'intel') && (github.event.pull_request.draft == false) }}
    name: preci-linux
    needs: preci-linux-build
    uses: ./.github/workflows/_linux_ut.yml
    with:
      ut: op_regression,op_regression_dev1,op_transformers,op_extended,op_ut,xpu_distributed
      runner: linux.idc.xpu

  Inductor-XPU-E2E-CI-Tests:
    name: preci-linux / e2e_test
    needs: preci-linux-build
    runs-on: pvc_e2e
    env:
      GH_TOKEN: ${{ github.token }}
    # Don't run on forked repos and draft PRs
    if: ${{ (github.repository_owner == 'intel') && (github.event.pull_request.draft == false) }}
    timeout-minutes: 900
    steps:
      - name: Prepare Env
        run: |
          # Cleanup workspace
          rm -rf ${{ github.workspace }}/*
          which conda && conda clean -ay
          conda remove --all -y -n xpu_op_${ZE_AFFINITY_MASK} || \
                rm -rf $(dirname ${CONDA_EXE})/../envs/xpu_op_${ZE_AFFINITY_MASK}
          conda create -n xpu_op_${ZE_AFFINITY_MASK} python=${{ inputs.python }} cmake ninja -y
      - name: Checkout Torch-xpu-ops
        uses: actions/checkout@v4
        with:
          path: torch-xpu-ops
      - name: Download Pytorch Wheel
        uses: actions/download-artifact@v4
        with:
          name: Torch-XPU-Wheel-${{ github.event.pull_request.number || github.sha }}
          path: ${{ github.workspace }}
      - name: Prepare Pytorch
        id: torch_info
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          pip install --force-reinstall ${{ github.workspace }}/torch*.whl
          TORCH_BRANCH_ID=$(python -c 'import torch; print(torch.__version__)')
          TORCH_COMMIT_ID=$(python -c 'import torch; print(torch.version.git_version)')
          rm -rf ./pytorch
          git clone https://github.com/pytorch/pytorch ./pytorch
          cd ./pytorch
          git checkout $TORCH_COMMIT_ID
          pip install -r .ci/docker/requirements-ci.txt
          pip install requests
          python ${{ github.workspace }}/torch-xpu-ops/.github/scripts/apply_torch_pr.py
          echo "TORCH_BRANCH_ID=${TORCH_BRANCH_ID}" |tee -a "${GITHUB_OUTPUT}" >> "${GITHUB_ENV}"
          echo "TORCH_COMMIT_ID=${TORCH_COMMIT_ID}" |tee -a "${GITHUB_OUTPUT}" >> "${GITHUB_ENV}"
      - name: Deps Installation
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ./pytorch
          TRITON_REPO="https://github.com/intel/intel-xpu-backend-for-triton"
          TRITON_COMMIT_ID="$(cat .ci/docker/ci_commit_pins/triton-xpu.txt)"
          echo ${TRITON_REPO}@${TRITON_COMMIT_ID}
          pip install --force-reinstall "git+${TRITON_REPO}@${TRITON_COMMIT_ID}#subdirectory=python"
      - name: Torch Config
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          python -c "import torch; print(torch.__config__.show())"
          python -c "import torch; print(torch.__config__.parallel_info())"
          python -c "import torch; print(torch.__config__.torch.xpu.device_count())"
          python -c "import triton; print(triton.__version__)"
          python pytorch/torch/utils/collect_env.py
          xpu-smi discovery
      - name: Identify pinned versions
        run: |
          source torch-xpu-ops/.github/scripts/env.sh
          cd ./pytorch
          echo "TORCHVISION_COMMIT_ID=$(<.github/ci_commit_pins/vision.txt)" >> "${GITHUB_ENV}"
          echo "TORCHBENCH_COMMIT_ID=$(<.github/ci_commit_pins/torchbench.txt)" >> "${GITHUB_ENV}"
          echo "TORCHAUDIO_COMMIT_ID=$(<.github/ci_commit_pins/audio.txt)" >> "${GITHUB_ENV}"
          echo "TRANSFORMERS_VERSION=$(<.ci/docker/ci_commit_pins/huggingface.txt)" >> "${GITHUB_ENV}"
          echo "TIMM_COMMIT_ID=$(<.ci/docker/ci_commit_pins/timm.txt)" >> "${GITHUB_ENV}"
      - name: Torch Config
        run: |
          echo "$GITHUB_ENV"
          rm -rf ./pytorch/inductor_log
          rm -rf /tmp/torchinductor_*
          rm -rf ~/.triton/cache

      - name: Huggingface BF16 Training Test
        uses: ./.github/actions/inductor-xpu-e2e-test
        with:
          suite: huggingface
          dt: bfloat16
          mode: training
          scenario: accuracy,performance
          env_prepare: true
          hf_token: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
      - name: Huggingface FP16 Training Test
        uses: ./.github/actions/inductor-xpu-e2e-test
        with:
          suite: huggingface
          dt: float16
          mode: training
          scenario: accuracy,performance
          hf_token: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
      - name: Timm_models BF16 Training Test
        uses: ./.github/actions/inductor-xpu-e2e-test
        with:
          suite: timm_models
          dt: bfloat16
          mode: training
          scenario: accuracy,performance
          env_prepare: true
          hf_token: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
      - name: Torchbench BF16 Training Test
        uses: ./.github/actions/inductor-xpu-e2e-test
        with:
          suite: torchbench
          dt: bfloat16
          mode: training
          scenario: accuracy,performance
          env_prepare: true
          hf_token: ${{ secrets.HUGGING_FACE_HUB_TOKEN }}
      - name: Summarize archieve files
        if: ${{ ! cancelled() }}
        run: |
          rm -rf ${{ github.workspace }}/upload_files
          cp -r ${{ github.workspace }}/pytorch/inductor_log ${{ github.workspace }}/upload_files
          # Print summary
          source activate e2e_ci
          export IS_PR=1
          bash ${{ github.workspace }}/torch-xpu-ops/.github/scripts/e2e_summary.sh \
              ${{ github.workspace }}/upload_files \
              Inductor-weekly-LTS-XPU-E2E \
          >> ${GITHUB_STEP_SUMMARY}
          exit_label=$(awk 'BEGIN{sum=0}{if($2>0){sum++}}END{print sum}' /tmp/tmp-result.txt)
          if [ ${exit_label} -ne 0 ];then
            grep -E "(Real failed|to passed|Warning timeout).*: [1-9]|Summary for" /tmp/tmp-*.txt |grep -E "failed|passed|timeout" -B 1
            echo "There are ${exit_label} cases that need look into!!! Please check them"
            exit ${exit_label}
          fi
      - name: Upload Inductor XPU E2E Data
        if: ${{ ! cancelled() }}
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-CI-XPU-E2E-Data-${{ github.event.pull_request.number || github.sha }}
          path: ${{ github.workspace }}/upload_files

  check-conditions:
    if: ${{ github.repository_owner == 'intel' }}
    name: preci-win-conditions-filter
    runs-on: ubuntu-22.04
    outputs:
      files-changed: ${{ steps.check-files.outputs.src_changed }}
      has-label: ${{ steps.check-label.outputs.results }}
    steps:
      - uses: dorny/paths-filter@v2
        id: check-files
        with:
          filters: |
            src_changed: 
              - 'cmake/**'
              - 'tools/**'
              - 'src/**.cmake'
              - 'CMakeLists.txt'
              - 'test/sycl/CMakeLists.txt'
              - 'src/xccl/CMakeLists.txt'
              - 'src/ATen/CMakeLists.txt'
              - 'src/CMakeLists.txt'
              - '.github/workflows/_windows_ut.yml'
      
      - name: Check Label
        id: check-label
        run: |
          LABEL_EXISTS=$(echo '${{ toJSON(github.event.pull_request.labels) }}' | jq 'any(.name == "windows_ci")')
          echo $LABEL_EXISTS
          echo "results=$LABEL_EXISTS" >> $GITHUB_OUTPUT

  preci-windows:
    # Don't run on forked repos and draft PRs
    if: ${{ (github.repository_owner == 'intel') && (github.event.pull_request.draft == false) }} 
    name: preci-windows
    needs: [preci-lint-check, check-conditions]
    uses: ./.github/workflows/_windows_ut.yml
    with: 
      ut: op_extended,torch_xpu
      runner: Windows_CI
      files-changed: ${{ needs.check-conditions.outputs.files-changed }}
      has-label: ${{ needs.check-conditions.outputs.has-label }}
