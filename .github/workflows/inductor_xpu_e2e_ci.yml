name: E2E CI Tests

on:
  workflow_dispatch:
  pull_request:
    branches: [main]
  merge_group:
    branches: [main]
    types: [checks_requested]

permissions: read-all

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  Inductor-XPU-E2E-CI-Tests:
    runs-on: pvc_e2e
    steps:
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Prepare Conda ENV
        run: |
          which conda
          if conda env list | grep -q "^e2e_ci "; then source activate e2e_ci; else conda create -n e2e_ci python=3.8 cmake ninja -y; fi
          conda install intel::mkl-static intel::mkl-include -y
          pip install pandas scipy tqdm
      - name: Prepare Stock Pytorch
        run: |
          pwd
          cd ../ && rm -rf pytorch
          git clone -b e2e-baseline https://github.com/etaf/pytorch-inductor-xpu pytorch
          cd pytorch && git log -n 1 && git submodule sync && git submodule update --init --recursive
          rm -rf third_party/torch-xpu-ops && cp -r ../torch-xpu-ops third_party/
          # Workaround for torch-xpu-ops ci test
          sed -i "s/checkout --quiet \${TORCH_XPU_OPS_COMMIT}/log -n 1/g" caffe2/CMakeLists.txt
      - name: Triton Installation
        run: |
          source activate e2e_ci
          TRITON_REPO="https://github.com/intel/intel-xpu-backend-for-triton"
          TRITON_PINNED_COMMIT=$(cat .github/ci_commit_pins/triton.txt)
          echo ${TRITON_REPO}@${TRITON_PINNED_COMMIT}
          pip install --force-reinstall "git+${TRITON_REPO}@${TRITON_PINNED_COMMIT}#subdirectory=python"
      - name: Build Pytorch XPU
        run: |
          source activate e2e_ci
          cd ../pytorch
          pip install -r requirements.txt
          export USE_XPU=1
          export PYTORCH_XPU_FALLBACK_OP=rsub.Scalar
          source /opt/intel/oneapi/compiler/latest/env/vars.sh
          export CMAKE_PREFIX_PATH=${CONDA_PREFIX:-"$(dirname $(which conda))/../"}
          python setup.py bdist_wheel
          pip install --force-reinstall dist/*.whl
      - name: E2E Test
        run: |
          source activate e2e_ci
          cp .github/scripts/inductor_xpu_test.sh ../pytorch
          cd ../pytorch
          TRANSFORMERS_COMMIT=$(cat .ci/docker/ci_commit_pins/huggingface.txt)
          pip install --force-reinstall git+https://github.com/huggingface/transformers@${TRANSFORMERS_COMMIT}
          source /opt/intel/oneapi/compiler/latest/env/vars.sh
          export PYTORCH_ENABLE_XPU_FALLBACK=1
          export PYTORCH_XPU_FALLBACK_OP=rsub.Scalar
          bash inductor_xpu_test.sh huggingface float32 inference accuracy xpu 0 static 8 0 & \
          bash inductor_xpu_test.sh huggingface float32 inference accuracy xpu 1 static 8 1 & \
          bash inductor_xpu_test.sh huggingface float32 inference accuracy xpu 2 static 8 2 & \
          bash inductor_xpu_test.sh huggingface float32 inference accuracy xpu 3 static 8 3 & \
          bash inductor_xpu_test.sh huggingface float32 inference accuracy xpu 4 static 8 4 & \
          bash inductor_xpu_test.sh huggingface float32 inference accuracy xpu 5 static 8 5 & \
          bash inductor_xpu_test.sh huggingface float32 inference accuracy xpu 6 static 8 6 & \
          bash inductor_xpu_test.sh huggingface float32 inference accuracy xpu 7 static 8 7 & wait
      - name: Test Results Overview
        run: |
          set +e
          cd ../pytorch/inductor_log/huggingface
          cd float32
          echo -e "============ Acc Check for HF float32 ============" | tee -a ./e2e_summary.log
          awk -i inplace '!seen[$0]++' inductor_huggingface_float32_inference_xpu_accuracy.csv
          csv_lines_inf=$(cat inductor_huggingface_float32_inference_xpu_accuracy.csv | wc -l)
          let num_total_float32=csv_lines_inf-1
          num_passed_float32_inf=$(grep -c "pass" inductor_huggingface_float32_inference_xpu_accuracy.csv)
          let num_failed_float32_inf=num_total_float32-num_passed_float32_inf
          float32_inf_acc_pass_rate=`awk 'BEGIN{printf "%.2f%%\n",('$num_passed_float32_inf'/'$num_total_float32')*100}'`
          echo "num_total_float32: $num_total_float32" | tee -a ./e2e_summary.log
          echo "num_passed_float32_inf: $num_passed_float32_inf" | tee -a ./e2e_summary.log
          echo "num_failed_float32_inf: $num_failed_float32_inf" | tee -a ./e2e_summary.log
          echo "float32_inf_acc_pass_rate: $float32_inf_acc_pass_rate" | tee -a ./e2e_summary.log
          cd ${{ github.workspace }} && cp -r ../pytorch/inductor_log .
      - name: Upload Inductor XPU E2E CI Data
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-XPU-E2E-CI-Data-${{ github.event.pull_request.number || github.ref }}
          path: ${{ github.workspace }}/inductor_log
      - name: Test Results Check
        run: |
          cd ../pytorch/inductor_log/huggingface
          cd float32
          num_passed_float32_inf=$(grep "num_passed_float32_inf:" e2e_summary.log | sed -e 's/.*://;s/[^0-9.]//')
          if [ $num_passed_float32_inf -lt 42 ]; then
            echo -e "[ERROR] Inductor E2E CI test for HF float32 inference passed_num < 42"
            exit 1
          fi
