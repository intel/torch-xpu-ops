name: Linux Unit Test

inputs:
  test_type:
    required: true
    type: string
    description: Test scope

permissions: read-all

runs:
  using: composite
  steps:
    - name: ut_regression
      shell: bash -xe {0}
      if: ${{ inputs.test_type == 'ut_regression' }}
      run: |
        cd pytorch/third_party/torch-xpu-ops/test/regressions
        pytest --timeout 600 -v --junit-xml=../../ut_log/ut_regression.xml
    - name: ut_transformers
      shell: bash -xe {0}
      if: ${{ inputs.test_type == 'ut_transformers' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        cd pytorch
        pytest --timeout 600 -v test/test_transformers.py -k xpu \
          --junit-xml=$GITHUB_WORKSPACE/ut_log/ut_transformers.xml
    - name: ut_extended
      shell: bash -xe {0}
      if: ${{ inputs.test_type == 'ut_extended' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        cd pytorch/third_party/torch-xpu-ops/test/xpu/extended
        timeout 3600 python run_test_with_skip.py
        cp ut_extended.xml $GITHUB_WORKSPACE/ut_log
    - name: ut_op
      shell: bash -xe {0}
      if: ${{ inputs.test_type == 'ut_op' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        export PYTORCH_ENABLE_XPU_FALLBACK=1
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        timeout 10000 python run_test_with_skip.py \
          2>$GITHUB_WORKSPACE/ut_log/ut_op/ut_op_with_skip_test_error.log | \
          tee $GITHUB_WORKSPACE/ut_log/ut_op/ut_op_with_skip_test.log
        cp *.xml $GITHUB_WORKSPACE/ut_log
        find ut_op_with_skip_nn ut_op_with_skip_quantization/core -type f -exec sh -c '
            dir_path=$(dirname "$1");
            case "$dir_path" in
                *"ut_op_with_skip_quantization/core"*)
                    dir_name="ut_op_with_skip_quantization_core";;
                *)
                    dir_name=$(basename "$dir_path");;
            esac;
            mv "$1" "$dir_path/${dir_name}_$(basename "$1")"
        ' _ {} \;
        cp ut_op_with_skip_nn/*.xml $GITHUB_WORKSPACE/ut_log
        cp ut_op_with_skip_quantization/core/*.xml $GITHUB_WORKSPACE/ut_log
        # Cases run with a on-demand white list, since some suites are too
        # slow to go through all operators on CPU. So add cases on-demand
        # when XPU implementatoin is done.
        # test_foreach, test_decomp
        # Run with only
        timeout 10000 python run_test_with_only.py \
          2>$GITHUB_WORKSPACE/ut_log/ut_op/ut_op_with_only_test_error.log | \
          tee $GITHUB_WORKSPACE/ut_log/ut_op/ut_op_with_only_test.log
        cp ut_op_with_only.xml $GITHUB_WORKSPACE/ut_log
    - name: torch_xpu
      shell: bash -xe {0}
      if: ${{ inputs.test_type == 'torch_xpu' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        export PYTORCH_TESTING_DEVICE_ONLY_FOR="xpu"
        cd pytorch
        test_cmd="python test/run_test.py --include "
        for test in $(ls test/inductor | grep test); do test_cmd="${test_cmd} inductor/$test"; done
        for test in $(ls test/xpu | grep test); do test_cmd="${test_cmd} xpu/$test"; done
        if [ -f "test/test_xpu.py" ]; then test_cmd="${test_cmd} test_xpu.py"; fi
        eval $test_cmd 2>$GITHUB_WORKSPACE/ut_log/torch_xpu/torch_xpu_test_error.log | \
          tee $GITHUB_WORKSPACE/ut_log/torch_xpu/torch_xpu_test.log
    - name: ut_profiling
      shell: bash -xe {0}
      if: ${{ inputs.test_type == 'ut_profiling' }}
      run: |
        mkdir -p ut_log/profile_test/issue_reproduce
        cd pytorch/third_party/torch-xpu-ops
        # RN50 Test
        PROFILE=1 python -u test/profiling/rn50.py -a resnet50 --dummy ./ --num-iterations 20 --xpu 0
        cp profiling.fp32.train.pt $GITHUB_WORKSPACE/ut_log/profile_test
        # All Issue Reproduce UT
        python -u test/profiling/correlation_id_mixed.py | \
          tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/correlation_id_mixed.log
        python -u test/profiling/reproducer.missing.gpu.kernel.time.py | \
          tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/reproducer.missing.gpu.kernel.time.log
        python -u test/profiling/time_precision_in_profile.py | \
          tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/time_precision_in_profile.log
        python -u test/profiling/profile_partial_runtime_ops.py | \
          tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/profile_partial_runtime_ops.log
        python -u test/profiling/triton_xpu_ops_time.py | \
          tee $GITHUB_WORKSPACE/ut_log/profile_test/issue_reproduce/triton_xpu_ops_time.log
        # All xpu ut under test/profiler
        cd ../pytorch/test/profiler
        python -m pytest --timeout 600 -vs test_cpp_thread.py | \
          tee $GITHUB_WORKSPACE/ut_log/profile_test/test_cpp_thread.log
        python -m pytest --timeout 600 -vs test_execution_trace.py | \
          tee $GITHUB_WORKSPACE/ut_log/profile_test/test_execution_trace.log
        python -m pytest --timeout 600 -vs test_memory_profiler.py | \
          tee $GITHUB_WORKSPACE/ut_log/profile_test/test_memory_profiler.log
        python -m pytest --timeout 600 -vs test_profiler_tree.py | \
          tee $GITHUB_WORKSPACE/ut_log/profile_test/test_profiler_tree.log

    - name: xpu_dev1
      shell: bash -xe {0}
      if: ${{ inputs.test_type == 'xpu_dev1' }}
      run: |
        mkdir -p ut_log/xpu_dev1
        cd pytorch/third_party/torch-xpu-ops/test/regressions
        pytest --timeout 200 -v test_operation_on_device_1.py \
          --junit-xml=$GITHUB_WORKSPACE/ut_log/xpu_dev1.xml \
          2>${{ github.workspace }}/ut_log/xpu_dev1/xpu_dev1_test_error.log | \
          tee ${{ github.workspace }}/ut_log/xpu_dev1/xpu_dev1_test.log

    - name: xpu_distributed
      shell: bash -x -e -o pipefail {0}
      if: ${{ inputs.test_type == 'xpu_distributed' }}
      run: |
        mkdir -p ut_log/xpu_distributed
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        XCCL_ENABLE=$(python -c "import torch;print(torch.distributed.is_xccl_available())")
        if [[ "${XCCL_ENABLE,,}" == 'false' ]] || [[ "${XCCL_ENABLE}" == '0' ]]; then
          echo -e "[ERROR] XCCL is not enabled"
          exit 1
        fi
        timeout 1800 python run_distributed.py \
          2>${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test_error.log | \
          tee ${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test.log
