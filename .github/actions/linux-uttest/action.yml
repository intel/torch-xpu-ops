name: Linux Unit Test
description: Linux Unit Test

inputs:
  ut_name:
    required: true
    description: Which ut to launch

runs:
  using: composite
  steps:
    - name: Check Python
      shell: bash -xe {0}
      run: |
        which python && python -V
        which pip && pip list
        cp ${GITHUB_WORKSPACE}/.github/scripts/conftest.py pytorch/third_party/torch-xpu-ops/
    - name: op_regression
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_regression' || inputs.ut_name == 'basic' }}
      run: |
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch/third_party/torch-xpu-ops/test/regressions
        pytest --junit-xml=${{ github.workspace }}/ut_log/op_regression.xml \
          2> ${log_dir}/op_regression_test_error.log |tee ${log_dir}/op_regression_test.log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/regressions" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression.log
    - name: op_regression_dev1
      shell: timeout 300 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_regression_dev1' || inputs.ut_name == 'basic' }}
      run: |
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch/third_party/torch-xpu-ops/test/regressions
        timeout 180 pytest test_operation_on_device_1.py \
          --junit-xml=${{ github.workspace }}/ut_log/op_regression_dev1.xml \
          2> ${log_dir}/op_regression_dev1_test_error.log |tee ${log_dir}/op_regression_dev1_test.log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/regressions" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression_dev1.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression_dev1.log
    - name: op_transformers
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_transformers' || inputs.ut_name == 'basic' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch
        pytest test/test_transformers.py -k xpu \
          --junit-xml=${{ github.workspace }}/ut_log/op_transformers.xml \
          2> ${log_dir}/op_transformers_test_error.log |tee ${log_dir}/op_transformers_test.log
        echo -e "File Path: cd pytorch" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_transformers.log
        echo -e "Reproduce Command: pytest -sv test/failed_case -k xpu" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_transformers.log
    - name: op_extended
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_extended' || inputs.ut_name == 'basic' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch/third_party/torch-xpu-ops/test/xpu/extended
        python run_test_with_skip.py \
          2> ${log_dir}/op_extended_test_error.log |tee ${log_dir}/op_extended_test.log
        ls -al
        cp *.xml ${{ github.workspace }}/ut_log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/xpu/extended" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_extended.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_extended.log
    - name: op_ut
      shell: timeout 72000 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_ut' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        mkdir -p ut_log/op_ut
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        python run_test_with_skip.py \
          2> ${{ github.workspace }}/ut_log/op_ut/op_ut_with_skip_test_error.log | \
          tee ${{ github.workspace }}/ut_log/op_ut/op_ut_with_skip_test.log
        find . -type f -name "op_ut_with_*.xml" -exec mv {} ${{ github.workspace }}/ut_log/ \; || true
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/xpu" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_ut.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_ut.log
    - name: skipped_ut
      shell: timeout 72000 bash -xe {0}
      if: ${{ inputs.ut_name == 'skipped_ut' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        mkdir -p ut_log/skipped_ut
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        python run_test_with_skip.py --test-cases skipped \
          2> ${{ github.workspace }}/ut_log/skipped_ut/skipped_ut_with_skip_test_error.log | \
          tee ${{ github.workspace }}/ut_log/skipped_ut/skipped_ut_with_skip_test.log
        find . -type f -name "op_ut_with_*.xml" -exec mv {} ${{ github.workspace }}/ut_log/ \; || true
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/xpu" | tee -a ${{ github.workspace }}/ut_log/reproduce_skipped_ut.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_skipped_ut.log
    - name: torch_xpu
      shell: timeout 72000 bash -xe {0}
      if: ${{ inputs.ut_name == 'torch_xpu' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        export PYTORCH_TESTING_DEVICE_ONLY_FOR="xpu"
        mkdir -p ut_log/torch_xpu
        cd pytorch
        test_cmd="python test/run_test.py --include "
        for test in $(ls test/inductor | grep test); do test_cmd="${test_cmd} inductor/$test"; done
        for test in $(ls test/xpu | grep test); do test_cmd="${test_cmd} xpu/$test"; done
        if [ -f "test/test_xpu.py" ]; then test_cmd="${test_cmd} test_xpu.py"; fi
        eval $test_cmd 2> ${{ github.workspace }}/ut_log/torch_xpu/torch_xpu_test_error.log | \
          tee ${{ github.workspace }}/ut_log/torch_xpu/torch_xpu_test.log
    - name: xpu_profiling
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'xpu_profiling' }}
      run: |
        mkdir -p ut_log/xpu_profiling/issue_reproduce
        cd pytorch/third_party/torch-xpu-ops
        # RN50 Test
        PROFILE=1 python -u test/profiling/rn50.py -a resnet50 --dummy ./ --num-iterations 20 --xpu 0
        cp profiling.fp32.train.pt ${{ github.workspace }}/ut_log/xpu_profiling
        # All Issue Reproduce UT
        python -u test/profiling/correlation_id_mixed.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/correlation_id_mixed.log
        python -u test/profiling/reproducer.missing.gpu.kernel.time.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/reproducer.missing.gpu.kernel.time.log
        python -u test/profiling/time_precision_in_profile.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/time_precision_in_profile.log
        python -u test/profiling/profile_partial_runtime_ops.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/profile_partial_runtime_ops.log
        python -u test/profiling/triton_xpu_ops_time.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/triton_xpu_ops_time.log

        # llama case for calls number test
        pip install transformers
        python test/profiling/llama.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/llama.log
        python .github/scripts/llama_summary.py -i ${{ github.workspace }}/ut_log/xpu_profiling/llama.log -o ${{ github.workspace }}/ut_log/xpu_profiling/llama_summary.csv

        # All xpu ut under test/profiler
        cd ../../test/profiler
        python -m pytest -s test_cpp_thread.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_cpp_thread.log
        python -m pytest -s test_execution_trace.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_execution_trace.log
        python -m pytest -s test_memory_profiler.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_memory_profiler.log
        python -m pytest -s -vs test_profiler_tree.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_profiler_tree.log

    - name: xpu_distributed
      shell: timeout 36000 bash -xeu -o pipefail {0}
      if: ${{ inputs.ut_name == 'xpu_distributed' }}
      run: |
        xpu-smi topology -m
        mkdir -p ut_log/xpu_distributed
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        XCCL_ENABLE=$(python -c "import torch;print(torch.distributed.is_xccl_available())")
        if [[ "${XCCL_ENABLE,,}" == 'false' ]] || [[ "${XCCL_ENABLE}" == '0' ]]; then
          echo -e "[ERROR] XCCL is not enabled"
          exit 1
        fi
        python run_distributed.py \
          2> ${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test_error.log | \
          tee ${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test.log
        find ../ -type f -name "*.xml" -exec cp {} ${{ github.workspace }}/ut_log/ \;

    - name: op_p0
      shell: timeout 72000 bash -xeu -o pipefail {0}
      if: ${{ inputs.ut_name == 'op_p0' }}
      run: |
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        export PYTORCH_ROOT_DIR="${{ github.workspace }}/pytorch"
        # Inductor
        cd ${PYTORCH_ROOT_DIR}/
        pytest test/inductor/test_aot_inductor.py \
          test/inductor/test_aot_inductor_package.py \
          test/inductor/test_cutlass_backend.py \
          test/inductor/test_kernel_benchmark.py \
          test/inductor/test_mkldnn_pattern_matcher.py \
          test/inductor/test_torchinductor.py \
          test/inductor/test_torchinductor_opinfo.py \
          test/inductor/test_triton_heuristics.py \
          test/inductor/test_triton_kernels.py \
          test/inductor/test_triton_syntax.py \
          test/inductor/test_triton_wrapper.py \
          --junit-xml=${{ github.workspace }}/ut_log/pytorch_inductor.xml \
          2> ${log_dir}/pytorch_inductor_test_error.log |tee ${log_dir}/pytorch_inductor_test.log

        # Non-inductor
        cd ${PYTORCH_ROOT_DIR}/
        pytest test/xpu/test_conv.py \
          test/xpu/test_fusion.py \
          test/xpu/test_gemm.py \
          --junit-xml=${{ github.workspace }}/ut_log/pytorch_non-inductor.xml \
          2> ${log_dir}/pytorch_non-inductor_test_error.log |tee ${log_dir}/pytorch_non-inductor_test.log
        cd ${PYTORCH_ROOT_DIR}/third_party/torch-xpu-ops/
        pytest test/xpu/test_binary_ufuncs_xpu.py \
          test/xpu/test_masked_xpu.py \
          test/xpu/test_ops_xpu.py \
          test/xpu/test_optim_xpu.py \
          test/xpu/test_shape_ops_xpu.py \
          test/xpu/test_unary_ufuncs_xpu.py \
          test/xpu/test_view_ops_xpu.py \
          --junit-xml=${{ github.workspace }}/ut_log/xpu_non-inductor.xml \
          2> ${log_dir}/xpu_non-inductor_test_error.log |tee ${log_dir}/xpu_non-inductor_test.log

        # Profiling
        cd ${PYTORCH_ROOT_DIR}/
        pytest test/profiler/test_cpp_thread.py \
          test/profiler/test_execution_trace.py \
          test/profiler/test_memory_profiler.py \
          test/profiler/test_profiler_tree.py \
          --junit-xml=${{ github.workspace }}/ut_log/pytorch_non-profiling.xml \
          2> ${log_dir}/pytorch_non-profiling_test_error.log |tee ${log_dir}/pytorch_non-profiling_test.log
        cd ${PYTORCH_ROOT_DIR}/third_party/torch-xpu-ops/
        pytest test/profiling/rn50.py \
          test/profiling/llama.py \
          test/profiling/correlation_id_mixed.py \
          test/profiling/profile_partial_runtime_ops.py \
          test/profiling/reproducer.missing.gpu.kernel.time.py \
          test/profiling/time_precision_in_profile.py \
          test/profiling/triton_xpu_ops_time.py \
          --junit-xml=${{ github.workspace }}/ut_log/xpu_non-profiling.xml \
          2> ${log_dir}/xpu_non-profiling_test_error.log |tee ${log_dir}/xpu_non-profiling_test.log

        # Distributed, on PVC >= 4 with XL8 enabled
        xpu-smi topology -m
        export PYTEST_ADDOPTS="-v --timeout 3600 --timeout_method=thread -n 1 --max-worker-restart 10000"
        cd ${PYTORCH_ROOT_DIR}/
        pytest test/distributed/_composable.fsdp/test_fully_shard_state_dict.py \
          test/distributed/_composable/fsdp/test_fully_shard_frozen.py \
          test/distributed/_composable/test_checkpoint.py \
          test/distributed/_composable/test_contract.py \
          test/distributed/_tools/test_fsdp2_mem_tracker.py \
          test/distributed/_tools/test_mem_tracker.py \
          test/distributed/_tools/test_memory_tracker.py \
          test/distributed/fsdp/test_fsdp_apply.py \
          test/distributed/fsdp/test_fsdp_checkpoint.py \
          test/distributed/fsdp/test_fsdp_clip_grad_norm.py \
          test/distributed/fsdp/test_fsdp_comm.py \
          test/distributed/fsdp/test_fsdp_comm_hooks.py \
          test/distributed/fsdp/test_fsdp_exec_order.py \
          test/distributed/fsdp/test_fsdp_fine_tune.py \
          test/distributed/fsdp/test_fsdp_flatten_params.py \
          test/distributed/fsdp/test_fsdp_fx.py \
          test/distributed/fsdp/test_fsdp_input.py \
          test/distributed/fsdp/test_fsdp_misc.py \
          test/distributed/fsdp/test_fsdp_multiple_forward.py \
          test/distributed/fsdp/test_fsdp_multiple_wrapping.py \
          test/distributed/fsdp/test_fsdp_sharded_grad_scaler.py \
          test/distributed/fsdp/test_fsdp_uneven.py \
          test/distributed/fsdp/test_fsdp_unshard_params.py \
          test/distributed/fsdp/test_utils.py \
          test/distributed/fsdp/test_wrap.py \
          test/distributed/pipelining/test_backward.py \
          test/distributed/pipelining/test_microbatch.py \
          test/distributed/tensor/test_math_ops.py \
          test/distributed/test_functional_api.py \
          --junit-xml=${{ github.workspace }}/ut_log/pytorch_non-distributed.xml \
          2> ${log_dir}/pytorch_non-distributed_test_error.log |tee ${log_dir}/pytorch_non-distributed_test.log
        cd ${PYTORCH_ROOT_DIR}/third_party/torch-xpu-ops
        pytest test/xpu/distributed/test_c10d_ops_xccl.py \
          test/xpu/distributed/test_c10d_xccl.py \
          --junit-xml=${{ github.workspace }}/ut_log/xpu_non-distributed.xml \
          2> ${log_dir}/xpu_non-distributed_test_error.log |tee ${log_dir}/xpu_non-distributed_test.log

        echo -e "File Path: cd ${PYTORCH_ROOT_DIR}/" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_p0.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_p0.log

    # Summary
    - name: UT Test Results Summary
      shell: timeout 180 bash -xe {0}
      run: |
        pip install junitparser
        python ./.github/scripts/check-ut.py -n ${{ inputs.ut_name }} -i ${{ github.workspace }}/ut_log/*.xml >> $GITHUB_STEP_SUMMARY || true
        # Check the failure logs
        if ls ${{ github.workspace }}/failures*.log 1> /dev/null 2>&1; then
          echo -e "Exist Failure logs"
          echo "Found Failure logs as below: "
          for file in ${{ github.workspace }}/failures*.log; do
            echo "  - $file"
            cp "$file" ${{ github.workspace }}/ut_log
          done
          echo -e "Failure logs Copied"
        else
          echo -e "No Failure logs"
        fi
        # Copied the passed logs
        if ls passed*.log 1> /dev/null 2>&1; then
          cp passed*.log ${{ github.workspace }}/ut_log
          echo -e "Passed logs Copied"
        else
          echo -e "No Passed logs"
        fi
        # Copied the Summary logs
        if ls category*.log 1> /dev/null 2>&1; then
          cp category*.log ${{ github.workspace }}/ut_log
          echo -e "Category logs Copied"
        else
          echo -e "No Category logs"
        fi
        if [ -e ut_failure_list.csv ];then
            cp ut_failure_list.csv ${{ github.workspace }}/ut_log/ut_failure_list.csv || true
        fi
