name: Linux Unit Test

inputs:
  ut_name:
    required: true
    type: string
    description: Which ut to launch

runs:
  using: composite
  steps:
    - name: Check Python
      shell: bash -xe {0}
      run: |
        which python && python -V
        which pip && pip list
    - name: op_regression
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_regression' || inputs.ut_name == 'basic' }}
      run: |
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch/third_party/torch-xpu-ops/test/regressions
        pytest --junit-xml=${{ github.workspace }}/ut_log/op_regression.xml \
          2> ${log_dir}/op_regression_test_error.log |tee ${log_dir}/op_regression_test.log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/regressions" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression.log
    - name: op_regression_dev1
      shell: timeout 300 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_regression_dev1' || inputs.ut_name == 'basic' }}
      run: |
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch/third_party/torch-xpu-ops/test/regressions
        timeout 180 pytest test_operation_on_device_1.py \
          --junit-xml=${{ github.workspace }}/ut_log/op_regression_dev1.xml \
          2> ${log_dir}/op_regression_dev1_test_error.log |tee ${log_dir}/op_regression_dev1_test.log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/regressions" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression_dev1.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression_dev1.log
    - name: op_transformers
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_transformers' || inputs.ut_name == 'basic' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch
        pytest test/test_transformers.py -k xpu \
          --junit-xml=${{ github.workspace }}/ut_log/op_transformers.xml \
          2> ${log_dir}/op_transformers_test_error.log |tee ${log_dir}/op_transformers_test.log
        echo -e "File Path: cd pytorch" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_transformers.log
        echo -e "Reproduce Command: pytest -sv test/failed_case -k xpu" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_transformers.log
    - name: op_extended
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_extended' || inputs.ut_name == 'basic' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch/third_party/torch-xpu-ops/test/xpu/extended
        python run_test_with_skip.py \
          2> ${log_dir}/op_extended_test_error.log |tee ${log_dir}/op_extended_test.log
        ls -al
        cp *.xml ${{ github.workspace }}/ut_log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/xpu/extended" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_extended.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_extended.log
    - name: op_ut
      shell: timeout 18000 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_ut' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        export PYTORCH_ENABLE_XPU_FALLBACK=1
        mkdir -p ut_log/op_ut
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        python run_test_with_skip.py \
          2> ${{ github.workspace }}/ut_log/op_ut/op_ut_with_skip_test_error.log | \
          tee ${{ github.workspace }}/ut_log/op_ut/op_ut_with_skip_test.log
        ls -al
        cp *.xml ${{ github.workspace }}/ut_log
        find op_ut_with_skip_nn op_ut_with_skip_quantization/core -type f -exec sh -c '
            dir_path=$(dirname "$1");
            case "$dir_path" in
                *"op_ut_with_skip_quantization/core"*)
                    dir_name="op_ut_with_skip_quantization_core";;
                *)
                    dir_name=$(basename "$dir_path");;
            esac;
            mv "$1" "$dir_path/${dir_name}_$(basename "$1")"
        ' _ {} \;
        ls -al op_ut_with_skip_nn op_ut_with_skip_quantization/core
        cp op_ut_with_skip_nn/*.xml ${{ github.workspace }}/ut_log
        cp op_ut_with_skip_quantization/core/*.xml ${{ github.workspace }}/ut_log
        # Cases run with a on-demand white list, since some suites are too
        # slow to go through all operators on CPU. So add cases on-demand
        # when XPU implementatoin is done.
        # test_foreach, test_decomp
        # Run with only
        python run_test_with_only.py \
          2> ${{ github.workspace }}/ut_log/op_ut/op_ut_with_only_test_error.log | \
          tee ${{ github.workspace }}/ut_log/op_ut/op_ut_with_only_test.log
        ls -al
        cp *.xml ${{ github.workspace }}/ut_log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/xpu" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_ut.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_ut.log
    - name: op_skipped
      shell: timeout 18000 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_skipped' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        export PYTORCH_ENABLE_XPU_FALLBACK=1
        mkdir -p ut_log/op_skipped
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        python run_test_with_skip.py --test-cases skipped \
          2> ${{ github.workspace }}/ut_log/op_skipped/op_skipped_with_skip_test_error.log | \
          tee ${{ github.workspace }}/ut_log/op_skipped/op_skipped_with_skip_test.log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/xpu" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_skipped.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_skipped.log
        cp *.xml ${{ github.workspace }}/ut_log
    - name: torch_xpu
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'torch_xpu' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        export PYTORCH_TESTING_DEVICE_ONLY_FOR="xpu"
        mkdir -p ut_log/torch_xpu
        cd pytorch
        test_cmd="python test/run_test.py --include "
        for test in $(ls test/inductor | grep test); do test_cmd="${test_cmd} inductor/$test"; done
        for test in $(ls test/xpu | grep test); do test_cmd="${test_cmd} xpu/$test"; done
        if [ -f "test/test_xpu.py" ]; then test_cmd="${test_cmd} test_xpu.py"; fi
        eval $test_cmd 2> ${{ github.workspace }}/ut_log/torch_xpu/torch_xpu_test_error.log | \
          tee ${{ github.workspace }}/ut_log/torch_xpu/torch_xpu_test.log
    - name: xpu_profiling
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'xpu_profiling' }}
      run: |
        mkdir -p ut_log/xpu_profiling/issue_reproduce
        cd pytorch/third_party/torch-xpu-ops
        # RN50 Test
        PROFILE=1 python -u test/profiling/rn50.py -a resnet50 --dummy ./ --num-iterations 20 --xpu 0
        cp profiling.fp32.train.pt ${{ github.workspace }}/ut_log/xpu_profiling
        # All Issue Reproduce UT
        python -u test/profiling/correlation_id_mixed.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/correlation_id_mixed.log
        python -u test/profiling/reproducer.missing.gpu.kernel.time.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/reproducer.missing.gpu.kernel.time.log
        python -u test/profiling/time_precision_in_profile.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/time_precision_in_profile.log
        python -u test/profiling/profile_partial_runtime_ops.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/profile_partial_runtime_ops.log
        python -u test/profiling/triton_xpu_ops_time.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/triton_xpu_ops_time.log

        # llama case for calls number test
        pip install transformers
        python test/profiling/llama.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/llama.log
        python .github/scripts/llama_summary.py -i ${{ github.workspace }}/ut_log/xpu_profiling/llama.log -o ${{ github.workspace }}/ut_log/xpu_profiling/llama_summary.csv

        # All xpu ut under test/profiler
        cd ../../test/profiler
        python -m pytest -s test_cpp_thread.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_cpp_thread.log
        python -m pytest -s test_execution_trace.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_execution_trace.log
        python -m pytest -s test_memory_profiler.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_memory_profiler.log
        python -m pytest -s -vs test_profiler_tree.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_profiler_tree.log

    - name: xpu_distributed
      shell: timeout 36000 bash -xeu -o pipefail {0}
      if: ${{ inputs.ut_name == 'xpu_distributed' }}
      run: |
        xpu-smi topology -m
        mkdir -p ut_log/xpu_distributed
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        XCCL_ENABLE=$(python -c "import torch;print(torch.distributed.is_xccl_available())")
        if [[ "${XCCL_ENABLE,,}" == 'false' ]] || [[ "${XCCL_ENABLE}" == '0' ]]; then
          echo -e "[ERROR] XCCL is not enabled"
          exit 1
        fi
        export CCL_ROOT=$(dirname $(which python))/../
        export PATH="${CCL_ROOT}/bin/libfabric:${PATH}"
        export LD_LIBRARY_PATH="${CCL_ROOT}/lib:${LD_LIBRARY_PATH}"
        python run_distributed.py \
          2> ${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test_error.log | \
          tee ${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test.log
        find ../ -type f -name "*.xml" -exec cp {} ${{ github.workspace }}/ut_log/ \;

    # Summary
    - name: UT Test Results Summary
      shell: timeout 180 bash -xe {0}
      run: |
        pip install junitparser
        python ./.github/scripts/check-ut.py ${{ github.workspace }}/ut_log/*.xml >> $GITHUB_STEP_SUMMARY || true
        # Check the failure logs
        if ls ${{ github.workspace }}/failures*.log 1> /dev/null 2>&1; then
          echo -e "Exist Failure logs"
          echo "Found Failure logs as below: "
          for file in ${{ github.workspace }}/failures*.log; do
            echo "  - $file"
            cp "$file" ${{ github.workspace }}/ut_log
          done
          echo -e "Failure logs Copied"
        else
          echo -e "No Failure logs"
        fi
        # Copied the passed logs
        if ls passed*.log 1> /dev/null 2>&1; then
          cp passed*.log ${{ github.workspace }}/ut_log
          echo -e "Passed logs Copied"
        else
          echo -e "No Passed logs"
        fi
        # Copied the Summary logs
        if ls category*.log 1> /dev/null 2>&1; then
          cp category*.log ${{ github.workspace }}/ut_log
          echo -e "Category logs Copied"
        else
          echo -e "No Category logs"
        fi
        if [ -e ut_failure_list.csv ];then
            cp ut_failure_list.csv ${{ github.workspace }}/ut_log/ut_failure_list.csv || true
        fi
