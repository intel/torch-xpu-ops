name: Linux Unit Test

inputs:
  ut_name:
    required: true
    type: string
    description: Which ut to launch

runs:
  using: composite
  steps:
    - name: Check Python
      shell: bash -xe {0}
      run: |
        which python && python -V
        which pip && pip list
        cp ${GITHUB_WORKSPACE}/.github/scripts/conftest.py pytorch/third_party/torch-xpu-ops/
    - name: op_regression
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_regression' || inputs.ut_name == 'basic' }}
      run: |
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch/third_party/torch-xpu-ops/test/regressions
        pytest --junit-xml=${{ github.workspace }}/ut_log/op_regression.xml \
          2> ${log_dir}/op_regression_test_error.log |tee ${log_dir}/op_regression_test.log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/regressions" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression.log
    - name: op_regression_dev1
      shell: timeout 300 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_regression_dev1' || inputs.ut_name == 'basic' }}
      run: |
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch/third_party/torch-xpu-ops/test/regressions
        timeout 180 pytest test_operation_on_device_1.py \
          --junit-xml=${{ github.workspace }}/ut_log/op_regression_dev1.xml \
          2> ${log_dir}/op_regression_dev1_test_error.log |tee ${log_dir}/op_regression_dev1_test.log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/regressions" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression_dev1.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_regression_dev1.log
    - name: op_transformers
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_transformers' || inputs.ut_name == 'basic' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch
        pytest test/test_transformers.py -k xpu \
          --junit-xml=${{ github.workspace }}/ut_log/op_transformers.xml \
          2> ${log_dir}/op_transformers_test_error.log |tee ${log_dir}/op_transformers_test.log
        echo -e "File Path: cd pytorch" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_transformers.log
        echo -e "Reproduce Command: pytest -sv test/failed_case -k xpu" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_transformers.log
    - name: op_extended
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_extended' || inputs.ut_name == 'basic' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        log_dir="${{ github.workspace }}/ut_log/${{ inputs.ut_name }}"
        mkdir -p ${log_dir}
        cd pytorch/third_party/torch-xpu-ops/test/xpu/extended
        python run_test_with_skip.py \
          2> ${log_dir}/op_extended_test_error.log |tee ${log_dir}/op_extended_test.log
        ls -al
        cp *.xml ${{ github.workspace }}/ut_log
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/xpu/extended" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_extended.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_extended.log
    - name: op_ut
      shell: timeout 72000 bash -xe {0}
      if: ${{ inputs.ut_name == 'op_ut' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        mkdir -p ut_log/op_ut
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        python run_test_with_skip.py \
          2> ${{ github.workspace }}/ut_log/op_ut/op_ut_with_skip_test_error.log | \
          tee ${{ github.workspace }}/ut_log/op_ut/op_ut_with_skip_test.log
        find . -type f -name "op_ut_with_*.xml" -exec mv {} ${{ github.workspace }}/ut_log/ \; || true
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/xpu" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_ut.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_op_ut.log
    - name: skipped_ut
      shell: timeout 72000 bash -xe {0}
      if: ${{ inputs.ut_name == 'skipped_ut' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        mkdir -p ut_log/skipped_ut
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        python run_test_with_skip.py --test-cases skipped \
          2> ${{ github.workspace }}/ut_log/skipped_ut/skipped_ut_with_skip_test_error.log | \
          tee ${{ github.workspace }}/ut_log/skipped_ut/skipped_ut_with_skip_test.log
        find . -type f -name "op_ut_with_*.xml" -exec mv {} ${{ github.workspace }}/ut_log/ \; || true
        echo -e "File Path: cd pytorch/third_party/torch-xpu-ops/test/xpu" | tee -a ${{ github.workspace }}/ut_log/reproduce_skipped_ut.log
        echo -e "Reproduce Command: pytest -sv failed_case" | tee -a ${{ github.workspace }}/ut_log/reproduce_skipped_ut.log
    - name: xpu_inductor
      shell: timeout 36000 bash -xe {0}
      if: ${{ inputs.ut_name == 'xpu_inductor' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        export PYTORCH_TESTING_DEVICE_ONLY_FOR="xpu"
        mkdir -p ut_log/xpu_inductor
        cd pytorch
        for file in "test/inductor"/test*.py; do
          filename=$(basename "$file")
          echo "=== Starting test: $filename ==="
          start=$(date +%s)
          pytest -sv test/inductor/$filename --junit-xml=${{ github.workspace }}/ut_log/inductor_$filename.xml 2>${{ github.workspace }}/ut_log/xpu_inductor/xpu_inductor_${filename}_test_error.log | \
              tee ${{ github.workspace }}/ut_log/xpu_inductor/xpu_inductor_${filename}_test.log
          end=$(date +%s)
          echo -e "$filename duration: $((end - start))s"
          echo "=== Finished test: $filename ==="
        done
    - name: test_xpu
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'test_xpu' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        export PYTORCH_TESTING_DEVICE_ONLY_FOR="xpu"
        mkdir -p ut_log/test_xpu
        cd pytorch
        if [ -f "test/test_xpu.py" ]; then
          pytest -sv test/test_xpu.py --junit-xml=${{ github.workspace }}/ut_log/test_xpu.xml \
            2> ${{ github.workspace }}/ut_log/test_xpu/test_xpu_error.log | \
            tee ${{ github.workspace }}/ut_log/test_xpu/test_xpu.log
        fi
    - name: torch_xpu
      shell: timeout 72000 bash -xe {0}
      if: ${{ inputs.ut_name == 'torch_xpu' }}
      run: |
        export PYTORCH_TEST_WITH_SLOW=1
        export PYTORCH_TESTING_DEVICE_ONLY_FOR="xpu"
        mkdir -p ut_log/torch_xpu
        cd pytorch
        for file in "test/xpu"/test*.py; do
          filename=$(basename "$file")
          pytest -sv test/xpu/$filename --junit-xml=${{ github.workspace }}/ut_log/torch_xpu_$filename.xml \
              2> ${{ github.workspace }}/ut_log/torch_xpu/torch_xpu_${filename}_error.log | \
              tee ${{ github.workspace }}/ut_log/torch_xpu/torch_xpu_${filename}.log
        done
    - name: xpu_profiling
      shell: timeout 3600 bash -xe {0}
      if: ${{ inputs.ut_name == 'xpu_profiling' }}
      run: |
        mkdir -p ut_log/xpu_profiling/issue_reproduce
        cd pytorch/third_party/torch-xpu-ops
        # RN50 Test
        PROFILE=1 python -u test/profiling/rn50.py -a resnet50 --dummy ./ --num-iterations 20 --xpu 0
        cp profiling.fp32.train.pt ${{ github.workspace }}/ut_log/xpu_profiling
        # All Issue Reproduce UT
        python -u test/profiling/correlation_id_mixed.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/correlation_id_mixed.log
        python -u test/profiling/reproducer.missing.gpu.kernel.time.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/reproducer.missing.gpu.kernel.time.log
        python -u test/profiling/time_precision_in_profile.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/time_precision_in_profile.log
        python -u test/profiling/profile_partial_runtime_ops.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/profile_partial_runtime_ops.log
        python -u test/profiling/triton_xpu_ops_time.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/triton_xpu_ops_time.log
        python -m pytest -s test/profiling/test_for_overlapping_kernels.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/issue_reproduce/test_for_overlapping_kernels.log

        # llama case for calls number test
        pip install transformers
        python test/profiling/llama.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/llama.log
        python .github/scripts/llama_summary.py -i ${{ github.workspace }}/ut_log/xpu_profiling/llama.log -o ${{ github.workspace }}/ut_log/xpu_profiling/llama_summary.csv

        # All xpu ut under test/profiler
        cd ../../test/profiler
        python -m pytest -s test_cpp_thread.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_cpp_thread.log
        python -m pytest -s test_execution_trace.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_execution_trace.log
        python -m pytest -s test_memory_profiler.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_memory_profiler.log
        python -m pytest -s -vs test_profiler_tree.py | \
          tee ${{ github.workspace }}/ut_log/xpu_profiling/test_profiler_tree.log

    - name: xpu_distributed
      shell: timeout 36000 bash -xeu -o pipefail {0}
      if: ${{ inputs.ut_name == 'xpu_distributed' }}
      run: |
        xpu-smi topology -m
        mkdir -p ut_log/xpu_distributed
        cd pytorch/third_party/torch-xpu-ops/test/xpu
        XCCL_ENABLE=$(python -c "import torch;print(torch.distributed.is_xccl_available())")
        if [[ "${XCCL_ENABLE,,}" == 'false' ]] || [[ "${XCCL_ENABLE}" == '0' ]]; then
          echo -e "[ERROR] XCCL is not enabled"
          exit 1
        fi
        python run_distributed.py \
          2> ${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test_error.log | \
          tee ${{ github.workspace }}/ut_log/xpu_distributed/xpu_distributed_test.log
        find ../ -type f -name "*.xml" -exec cp {} ${{ github.workspace }}/ut_log/ \;

    # Summary
    - name: UT Test Results Summary
      shell: timeout 180 bash -xe {0}
      run: |
        pip install junitparser
        python ./.github/scripts/check-ut.py -n ${{ inputs.ut_name }} -i ${{ github.workspace }}/ut_log/*.xml >> $GITHUB_STEP_SUMMARY || true
        # Check the failure logs
        if ls ${{ github.workspace }}/failures*.log 1> /dev/null 2>&1; then
          echo -e "Exist Failure logs"
          echo "Found Failure logs as below: "
          for file in ${{ github.workspace }}/failures*.log; do
            echo "  - $file"
            cp "$file" ${{ github.workspace }}/ut_log
          done
          echo -e "Failure logs Copied"
        else
          echo -e "No Failure logs"
        fi
        # Copied the passed logs
        if ls passed*.log 1> /dev/null 2>&1; then
          cp passed*.log ${{ github.workspace }}/ut_log
          echo -e "Passed logs Copied"
        else
          echo -e "No Passed logs"
        fi
        # Copied the Summary logs
        if ls category*.log 1> /dev/null 2>&1; then
          cp category*.log ${{ github.workspace }}/ut_log
          echo -e "Category logs Copied"
        else
          echo -e "No Category logs"
        fi
        if [ -e ut_failure_list.csv ];then
            cp ut_failure_list.csv ${{ github.workspace }}/ut_log/ut_failure_list.csv || true
        fi
