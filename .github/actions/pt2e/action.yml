name: inductor-xpu-pt2e-test
description: inductor-xpu-pt2e-test

inputs:
  dt:
    required: true
    default: 'float32'
    description: 'Data precision of the test. Options: float32,int8 (comma-separated)'
  scenario:
    required: true
    default: 'accuracy'
    description: 'Test scenario. Options: accuracy,performance (comma-separated)'
  pytorch:
    required: false
    default: 'main'
    description: 'Pytorch branch/commit (for reference, not used directly in this workflow)'

runs:
  using: composite
  steps:
    - name: Verify Python environment
      shell: bash -eo pipefail {0}
      run: |
        echo "=== Python Environment Verification ==="
        echo "Python executable: $(which python)"
        echo "Python version: $(python -V 2>&1)"
        echo ""
        echo "=== PIP Environment ==="
        pip --version || echo "pip not found"
        pip list --format=columns | head -10 || echo "pip list failed"

        echo -e "\n=== Test Configuration ==="
        echo "Data types: ${{ inputs.dt }}"
        echo "Scenarios: ${{ inputs.scenario }}"
        echo "PyTorch reference: ${{ inputs.pytorch }}"

    - name: Prepare ImageNet dataset
      shell: bash -eo pipefail {0}
      run: |
        echo "=== Preparing ImageNet Dataset ==="

        # Define dataset directory
        DATASET_DIR="${RUNNER_TEMP}/_datasets/imagenet"
        echo "Dataset directory: ${DATASET_DIR}"

        # Check if dataset already exists
        if [ -d "${DATASET_DIR}" ] && [ -f "${DATASET_DIR}/valprep.sh" ]; then
          echo "Dataset already exists at ${DATASET_DIR}"
          echo "dataset_dir=${DATASET_DIR}" >> "${GITHUB_ENV}"
          exit 0
        fi

        # Create directory and download dataset
        echo "Downloading and preparing ImageNet dataset..."
        rm -rf "${DATASET_DIR}"
        mkdir -p "${DATASET_DIR}"

        cd "${DATASET_DIR}" || {
          echo "Error: Failed to change to dataset directory"
          exit 1
        }

        # Download validation preparation script
        echo "Downloading validation preparation script..."
        wget -q --show-progress -O valprep.sh \
          https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh || {
          echo "Error: Failed to download valprep.sh"
          exit 1
        }

        chmod +x valprep.sh

        # Download ImageNet validation data
        echo "Downloading ImageNet validation dataset (may take several minutes)..."
        wget -q --show-progress \
          https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar || {
          echo "Error: Failed to download ImageNet dataset"
          exit 1
        }

        # Extract and prepare dataset
        echo "Extracting dataset..."
        tar -xf ILSVRC2012_img_val.tar || {
          echo "Error: Failed to extract dataset"
          exit 1
        }

        echo "Preparing validation dataset structure..."
        ./valprep.sh || {
          echo "Error: Failed to prepare validation dataset"
          exit 1
        }

        # Clean up tar file to save space
        rm -f ILSVRC2012_img_val.tar

        echo "Dataset preparation completed successfully"
        echo "Dataset size: $(du -sh ${DATASET_DIR} | cut -f1)"

        # Export dataset directory
        echo "dataset_dir=${DATASET_DIR}" >> "${GITHUB_ENV}"
        echo "Dataset ready at: ${DATASET_DIR}"

    - name: Execute PT2E Tests
      shell: bash -eo pipefail {0}
      env:
        DATASET_DIR: ${{ env.dataset_dir }}
      run: |
        echo "=== Executing PT2E Tests ==="
        echo "Data types: ${{ inputs.dt }}"
        echo "Scenarios: ${{ inputs.scenario }}"
        echo "Dataset directory: ${DATASET_DIR}"

        # Validate dataset directory
        if [ ! -d "${DATASET_DIR}" ]; then
          echo "Error: Dataset directory not found: ${DATASET_DIR}"
          exit 1
        fi

        # Define log directory
        PT2E_LOGS_DIR="${{ github.workspace }}/pytorch/inductor_log/pt2e"
        echo "Log directory: ${PT2E_LOGS_DIR}"

        # Clean and create log directory
        rm -rf "${PT2E_LOGS_DIR}"
        mkdir -p "${PT2E_LOGS_DIR}"

        # Initialize summary CSV
        SUMMARY_FILE="${PT2E_LOGS_DIR}/summary.csv"
        echo "Mode,Model,Dtype,Accuracy1,Accuracy5/Throughput,Status" > "${SUMMARY_FILE}"
        echo "Summary file created: ${SUMMARY_FILE}"

        # Helper function to parse input lists
        parse_comma_list() {
          local input="$1"
          # Remove spaces and split by comma
          echo "${input}" | tr -d ' ' | tr ',' ' '
        }

        # Parse inputs
        IFS=',' read -ra DT_ARRAY <<< "${{ inputs.dt }}"
        IFS=',' read -ra SCENARIO_ARRAY <<< "${{ inputs.scenario }}"

        # Helper function to check if value is in array
        contains_value() {
          local value="$1"
          shift
          local array=("$@")

          for item in "${array[@]}"; do
            if [[ "${item}" == "${value}" ]]; then
              return 0
            fi
          done
          return 1
        }

        # Helper function to extract accuracy from log
        extract_accuracy() {
          local log_file="$1"
          local model_name="$2"
          local dtype="$3"

          if [ ! -f "${log_file}" ]; then
            echo "Accuracy,${model_name},${dtype},failed,failed,Log file missing" >> "${SUMMARY_FILE}"
            return
          fi

          # Try to extract accuracy values
          local accuracy_line
          accuracy_line=$(grep -i 'Acc.1.*Acc.5' "${log_file}" | tail -n 1)

          if [ -n "${accuracy_line}" ]; then
            # Extract accuracy values (assuming format: Acc.1: X.XX% Acc.5: Y.YY%)
            local acc1 acc5
            acc1=$(echo "${accuracy_line}" | grep -o 'Acc.1:[[:space:]]*[0-9.]*%' | grep -o '[0-9.]*')
            acc5=$(echo "${accuracy_line}" | grep -o 'Acc.5:[[:space:]]*[0-9.]*%' | grep -o '[0-9.]*')

            if [ -n "${acc1}" ] && [ -n "${acc5}" ]; then
              echo "Accuracy,${model_name},${dtype},${acc1},${acc5},success" >> "${SUMMARY_FILE}"
              echo "Extracted accuracy for ${model_name} (${dtype}): Acc1=${acc1}%, Acc5=${acc5}%"
            else
              echo "Accuracy,${model_name},${dtype},failed,failed,Accuracy parsing failed" >> "${SUMMARY_FILE}"
            fi
          else
            echo "Accuracy,${model_name},${dtype},failed,failed,No accuracy results found" >> "${SUMMARY_FILE}"
          fi
        }

        # Helper function to extract throughput from log
        extract_throughput() {
          local log_file="$1"
          local model_name="$2"
          local quant_config="$3"
          local userbenchmark_dir="$4"

          if [ ! -d "${userbenchmark_dir}" ]; then
            echo "Performance,${model_name},${quant_config},failed,N/A,Userbenchmark directory missing" >> "${SUMMARY_FILE}"
            return
          fi

          # Try to extract throughput from userbenchmark results
          local throughput_line
          throughput_line=$(find "${userbenchmark_dir}" -type f -name "*.json" -o -name "*.txt" -o -name "*.log" 2>/dev/null | \
            xargs grep -l "eval_throughput" 2>/dev/null | \
            head -1 | xargs grep -i "eval_throughput" 2>/dev/null | \
            tail -n 1)

          if [ -n "${throughput_line}" ]; then
            # Extract throughput value (assuming it's the last number in the line)
            local throughput
            throughput=$(echo "${throughput_line}" | grep -o '[0-9.]*' | tail -n 1)

            if [ -n "${throughput}" ]; then
              echo "Performance,${model_name},${quant_config},${throughput},N/A,success" >> "${SUMMARY_FILE}"
              echo "Extracted throughput for ${model_name} (${quant_config}): ${throughput}"
            else
              echo "Performance,${model_name},${quant_config},failed,N/A,Throughput parsing failed" >> "${SUMMARY_FILE}"
            fi
          else
            echo "Performance,${model_name},${quant_config},failed,N/A,No throughput results found" >> "${SUMMARY_FILE}"
          fi
        }

        # Run accuracy tests
        if contains_value "accuracy" "${SCENARIO_ARRAY[@]}"; then
          echo -e "\n=== Running Accuracy Tests ==="

          # Define models for accuracy tests
          ACCURACY_MODELS=(
            "alexnet"
            "mnasnet1_0"
            "mobilenet_v2"
            "mobilenet_v3_large"
            "resnet152"
            "resnet18"
            "resnet50"
            "resnext50_32x4d"
            "shufflenet_v2_x1_0"
            "squeezenet1_1"
            "vgg16"
          )

          # Base command for accuracy tests
          ACCURACY_CMD="python pt2e-accuracy/scripts/modelbench/quant/inductor_quant_acc.py \
            --device xpu \
            --dataset_dir ${DATASET_DIR}"

          # Check if accuracy script exists
          if [ ! -f "pt2e-accuracy/scripts/modelbench/quant/inductor_quant_acc.py" ]; then
            echo "Error: Accuracy test script not found"
            exit 1
          fi

          # Run tests for each model and data type
          for model_name in "${ACCURACY_MODELS[@]}"; do
            echo "Testing model: ${model_name}"

            # Float32 tests
            if contains_value "float32" "${DT_ARRAY[@]}"; then
              echo "  Running float32 accuracy test..."
              LOG_FILE="${PT2E_LOGS_DIR}/accuracy-float32-${model_name}.log"

              ${ACCURACY_CMD} --model_list "${model_name}" --is_fp32 2>&1 | tee "${LOG_FILE}" || {
                echo "  Warning: Float32 test for ${model_name} failed or was interrupted"
              }

              extract_accuracy "${LOG_FILE}" "${model_name}" "float32"
            fi

            # Int8 tests
            if contains_value "int8" "${DT_ARRAY[@]}"; then
              echo "  Running int8 accuracy test..."
              LOG_FILE="${PT2E_LOGS_DIR}/accuracy-int8-${model_name}.log"

              ${ACCURACY_CMD} --model_list "${model_name}" 2>&1 | tee "${LOG_FILE}" || {
                echo "  Warning: Int8 test for ${model_name} failed or was interrupted"
              }

              extract_accuracy "${LOG_FILE}" "${model_name}" "int8"
            fi
          done

          echo "Accuracy tests completed"
        fi

        # Run performance tests
        if contains_value "performance" "${SCENARIO_ARRAY[@]}"; then
          echo -e "\n=== Running Performance Tests ==="

          # Define models for performance tests
          PERFORMANCE_MODELS=(
            "alexnet" "demucs" "dlrm" "hf_Albert" "hf_Bert" "hf_Bert_large"
            "hf_DistilBert" "hf_Roberta_base" "mnasnet1_0" "mobilenet_v2"
            "mobilenet_v3_large" "nvidia_deeprecommender" "pytorch_CycleGAN_and_pix2pix"
            "resnet152" "resnet18" "resnet50" "resnext50_32x4d"
            "shufflenet_v2_x1_0" "squeezenet1_1" "Super_SloMo"
            "timm_efficientnet" "timm_nfnet" "timm_regnet" "timm_resnest"
            "timm_vision_transformer" "timm_vision_transformer_large" "timm_vovnet"
            "vgg16"
          )

          # Base command for performance tests
          PERFORMANCE_CMD="python pt2e-performance/run_benchmark.py xpu \
            --test eval \
            --channels-last \
            --metrics throughputs \
            --torchdynamo inductor"

          # Check if performance script exists
          if [ ! -f "pt2e-performance/run_benchmark.py" ]; then
            echo "Error: Performance test script not found"
            exit 1
          fi

          # Run tests for each model and data type
          for model_name in "${PERFORMANCE_MODELS[@]}"; do
            echo "Testing model: ${model_name}"

            # Userbenchmark directory
            USERBENCHMARK_DIR="pt2e-performance/.userbenchmark"

            # Float32 tests
            if contains_value "float32" "${DT_ARRAY[@]}"; then
              echo "  Running float32 performance test..."
              LOG_FILE="${PT2E_LOGS_DIR}/performance-float32-${model_name}.log"

              # Clean previous results
              rm -rf "${USERBENCHMARK_DIR}"

              ${PERFORMANCE_CMD} -m "${model_name}" 2>&1 | tee "${LOG_FILE}" || {
                echo "  Warning: Float32 performance test for ${model_name} failed or was interrupted"
              }

              extract_throughput "${LOG_FILE}" "${model_name}" "float32" "${USERBENCHMARK_DIR}"
            fi

            # Int8 tests (ASYMM and SYMM configurations)
            if contains_value "int8" "${DT_ARRAY[@]}"; then
              # ASYMM configuration
              echo "  Running int8 ASYMM performance test..."
              LOG_FILE="${PT2E_LOGS_DIR}/performance-ASYMM-${model_name}.log"

              rm -rf "${USERBENCHMARK_DIR}"

              XPU_QUANT_CONFIG=ASYMM ${PERFORMANCE_CMD} -m "${model_name}" --quantization pt2e 2>&1 | tee "${LOG_FILE}" || {
                echo "  Warning: Int8 ASYMM performance test for ${model_name} failed or was interrupted"
              }

              extract_throughput "${LOG_FILE}" "${model_name}" "ASYMM" "${USERBENCHMARK_DIR}"

              # SYMM configuration
              echo "  Running int8 SYMM performance test..."
              LOG_FILE="${PT2E_LOGS_DIR}/performance-SYMM-${model_name}.log"

              rm -rf "${USERBENCHMARK_DIR}"

              XPU_QUANT_CONFIG=SYMM ${PERFORMANCE_CMD} -m "${model_name}" --quantization pt2e 2>&1 | tee "${LOG_FILE}" || {
                echo "  Warning: Int8 SYMM performance test for ${model_name} failed or was interrupted"
              }

              extract_throughput "${LOG_FILE}" "${model_name}" "SYMM" "${USERBENCHMARK_DIR}"
            fi
          done

          echo "Performance tests completed"
        fi

        # Generate final summary
        echo -e "\n=== Test Summary ==="
        echo "Total tests run: $(($(wc -l < "${SUMMARY_FILE}") - 1))"  # Subtract header

        # Count successes and failures
        success_count=$(grep -c ",success$" "${SUMMARY_FILE}" || echo "0")
        failure_count=$(grep -c ",failed" "${SUMMARY_FILE}" || echo "0")

        echo "Successful tests: ${success_count}"
        echo "Failed tests: ${failure_count}"

        # Display summary table
        echo -e "\n=== Detailed Summary ==="
        column -t -s ',' "${SUMMARY_FILE}" | head -20

        if [ "${failure_count}" -gt 0 ]; then
          echo -e "\n=== Failed Tests ==="
          grep ",failed" "${SUMMARY_FILE}" | column -t -s ','
        fi

        # List all log files
        echo -e "\n=== Generated Log Files ==="
        find "${PT2E_LOGS_DIR}" -name "*.log" -type f | sort | while read -r log_file; do
          echo "  $(basename "${log_file}")"
        done

        echo -e "\n=== PT2E Tests Completed ==="
